{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "060efaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(5000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "from pydub import AudioSegment\n",
    "from TTS.api import TTS\n",
    "from TTS.utils.manage import ModelManager\n",
    "import os\n",
    "import torch\n",
    "from TTS.utils.radam import RAdam\n",
    "import numpy.core.multiarray\n",
    "import shutil\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import random\n",
    "import tempfile\n",
    "\n",
    "torch.serialization.add_safe_globals([RAdam, numpy.core.multiarray.scalar])\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../Src/\")\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff9a81d-2d31-45b9-a4f2-f12f6183c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataSet = pd.read_csv('../Data/train_data.csv')\n",
    "#dataSet[dataSet['speaker_id'] == 'MMDM0']\n",
    "# outputDF = pd.read_csv('../Data/ttsOutputs/tts_models_en_ljspeech_tacotron2-DDC_generatedSentences.csv')\n",
    "# print(outputDF.shape[0])\n",
    "# uniqueSpeakers = outputDF['speakerId'].unique()\n",
    "# print(len(uniqueSpeakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9c0a27-d4ad-4074-8feb-7bd8bb600f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCsv(dataset):\n",
    "    return pd.read_csv(f'../Data/{dataset}_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41cf41d-3b0b-48cf-8bd3-34eb6b306a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeakers(df):\n",
    "    speakerIds = df['speaker_id']\n",
    "    return list(set(speakerIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3d89ff-453c-487a-933e-1d5a936f53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesBySpeaker(df,speakerId):\n",
    "    return df[df['speaker_id']==speakerId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fefcf4c0-622e-45e9-b934-8782e0a4be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenateAudio(speakerId, speakerDF,datasetName='train'):\n",
    "    if speakerDF.empty:\n",
    "        print(f\"Empty DataFrame for speaker {speakerId}. Skipping.\")\n",
    "        return\n",
    "    if datasetName == 'train':\n",
    "        finalAudioFile = f'../Data/concatenatedInputs/{speakerId}.wav'\n",
    "    else:\n",
    "        finalAudioFile = f'../Data/concatenatedTestInputs/{speakerId}.wav'\n",
    "    audioData = speakerDF[speakerDF['filename'].str.endswith('.wav', na=False)]\n",
    "\n",
    "    if audioData.empty:\n",
    "        print(f\"No .wav files for speaker {speakerId}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    audioFileList = audioData['path_from_data_dir']\n",
    "\n",
    "    if not exists(finalAudioFile):\n",
    "        concat_audio = AudioSegment.empty()\n",
    "    else:\n",
    "        concat_audio = AudioSegment.from_wav(finalAudioFile)\n",
    "    for audioFile in audioFileList:\n",
    "        try:\n",
    "            audio = AudioSegment.from_wav(f'../Data/data/{audioFile}') + AudioSegment.silent(duration=1000)\n",
    "            concat_audio += audio\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {audioFile}: {e}\")\n",
    "\n",
    "    if len(concat_audio) > 0:\n",
    "        concat_audio.export(finalAudioFile, format='wav')\n",
    "    else:\n",
    "        print(f\"No valid audio for speaker {speakerId}, nothing exported.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce46883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSentenceFromFile(sentenceFile):\n",
    "    try:\n",
    "        with open(f'../Data/data/{sentenceFile}', 'r') as file:\n",
    "            return \" \".join(file.read().strip().split(\" \")[2:])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read sentence file {sentenceFile}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31952130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAndNormalizeAudio(tts, sentence, inputAudioFile, outputAudioFile):\n",
    "    try:\n",
    "        print(f\"Generating audio for sentence: {sentence}\")\n",
    "        tts.tts_with_vc_to_file(\n",
    "            text=sentence,\n",
    "            file_path=outputAudioFile,\n",
    "            speaker_wav=inputAudioFile\n",
    "        )\n",
    "\n",
    "        # Normalize the generated audio\n",
    "        original_audio = AudioSegment.from_wav(inputAudioFile)\n",
    "        generated_audio = AudioSegment.from_wav(outputAudioFile)\n",
    "\n",
    "        gain = original_audio.dBFS - generated_audio.dBFS\n",
    "        normalized_audio = generated_audio.apply_gain(gain)\n",
    "\n",
    "        # Export the normalized audio back to the same file\n",
    "        normalized_audio.export(outputAudioFile, format='wav')\n",
    "        if not exists(outputAudioFile):\n",
    "            raise FileNotFoundError(f\"Output file {outputAudioFile} was not created.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to generate or normalize audio: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55d0bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveGeneratedSentences(speakerSentences, model_dir_name, modelDirectory):\n",
    "    outputFile = f'../Data/ttsOutputs/{model_dir_name}_generatedSentences.csv'\n",
    "    speakerSentencesJsonFile = f'../Data/ttsOutputs/{model_dir_name}_generatedSentences.json'\n",
    "    for resultFile in [outputFile, speakerSentencesJsonFile]:\n",
    "        os.makedirs(os.path.dirname(resultFile), exist_ok=True)\n",
    "    # Remove empty JSON file and directory if JSON is empty\n",
    "    if exists(speakerSentencesJsonFile):\n",
    "        try:\n",
    "            with open(speakerSentencesJsonFile, 'r') as f:\n",
    "                if not json.load(f):\n",
    "                    os.remove(speakerSentencesJsonFile)\n",
    "                    print(f\"Removed empty JSON file: {speakerSentencesJsonFile}\")\n",
    "                    shutil.rmtree(modelDirectory, ignore_errors=True)\n",
    "                    return\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking/removing JSON file: {e}\")\n",
    "\n",
    "    if speakerSentences:\n",
    "        try:\n",
    "            pd.DataFrame(speakerSentences).to_csv(outputFile, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save generated sentences: {e}\")\n",
    "            shutil.rmtree(modelDirectory, ignore_errors=True)\n",
    "            return\n",
    "\n",
    "    if not exists(outputFile):\n",
    "        print(f\"Warning: Output file {outputFile} was not created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efee4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGeneratedSentencesFromJson(speakerSentencesPath):\n",
    "    if exists(speakerSentencesPath):\n",
    "        with open(speakerSentencesPath, 'r') as f:\n",
    "            speakerSentences = json.load(f)\n",
    "    else:\n",
    "        speakerSentences = []\n",
    "    return speakerSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed9449a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTTS(model):\n",
    "    try:\n",
    "        # Scoped override of torch.load\n",
    "        original_torch_load = torch.load\n",
    "        torch.load = lambda *args, **kwargs: original_torch_load(*args, weights_only=False, **kwargs)\n",
    "        tts = TTS(model_name=model, progress_bar=False, gpu=False)\n",
    "        result = tts\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load TTS model {model}: {e}\")\n",
    "        result = None\n",
    "    finally:\n",
    "        torch.load = original_torch_load  # Restore the original torch.load\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b6ff992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_speaker(speaker, trainDF, tts, modelDirectory):\n",
    "    outputFilePath = f'{modelDirectory}/{speaker}.wav'\n",
    "    if exists(outputFilePath):\n",
    "        print(f\"Output file {outputFilePath} already exists. Skipping.\")\n",
    "        return None\n",
    "    speakerDF = getFilesBySpeaker(trainDF, speaker)\n",
    "    if speakerDF.empty:\n",
    "        print(f\"No data for speaker {speaker}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    textFiles = speakerDF[speakerDF['path_from_data_dir'].str.contains('.TXT', na=False)]\n",
    "    if textFiles.empty:\n",
    "        print(f\"No valid sentences for speaker {speaker}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    chosenSentenceFile = np.random.choice(textFiles['path_from_data_dir'])\n",
    "    matchingRealAudioFile = f\"../Data/data/{chosenSentenceFile.replace('.TXT', '.WAV.wav')}\"\n",
    "    if not exists(matchingRealAudioFile):\n",
    "        raise FileNotFoundError(f\"Matching audio file {matchingRealAudioFile} does not exist for speaker {speaker}.\")\n",
    "    chosenSentence = readSentenceFromFile(chosenSentenceFile)\n",
    "    if not chosenSentence:\n",
    "        print(f\"Chosen sentence for speaker {speaker} is empty. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    audioFile = f'../Data/concatenatedInputs/{speaker}.wav'\n",
    "    if not exists(audioFile):\n",
    "        print(f\"Audio file for {speaker} does not exist. Skipping.\")\n",
    "        return None\n",
    "    os.makedirs(os.path.dirname(outputFilePath), exist_ok=True)\n",
    "    if generateAndNormalizeAudio(tts, chosenSentence, audioFile, outputFilePath):\n",
    "        return {'speakerId': speaker, 'generatedSentence': chosenSentence}\n",
    "    elif generateAndNormalizeAudio(tts, chosenSentence, matchingRealAudioFile, outputFilePath):\n",
    "        return {'speakerId': speaker, 'generatedSentence': chosenSentence}\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d40c3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRawEnglishModelNames():\n",
    "    manager = ModelManager()\n",
    "    return [model for model in manager.list_models() if \"/en/\" in model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6506f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAudioInBatches(speakers, trainDF, batch_size=10):\n",
    "    if trainDF.empty or not speakers:\n",
    "        print(\"Empty dataset or no speakers provided. Exiting.\")\n",
    "        return\n",
    "\n",
    "    englishModels = getRawEnglishModelNames()\n",
    "\n",
    "    if not englishModels:\n",
    "        print(\"No English models found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    for model in englishModels:\n",
    "        print(f\"Processing model: {model}\")\n",
    "        model_dir_name = model.replace(\"/\", \"_\")\n",
    "        outputCSVFile = f'../Data/ttsOutputs/{model_dir_name}_generatedSentences.csv'\n",
    "        missing_speakers = list(speakers)\n",
    "        if exists(outputCSVFile):\n",
    "            outputDF = pd.read_csv(outputCSVFile)\n",
    "            processed_speakers = set(outputDF['speakerId'])\n",
    "            missing_speakers = list(set(speakers) - processed_speakers)  # <-- fix here\n",
    "            if not missing_speakers:\n",
    "                print(f\"All speakers processed for model {model}. Skipping.\")\n",
    "                continue\n",
    "            print(f'missing {len(missing_speakers)} speakers for model {model}')\n",
    "        \n",
    "        modelDirectory = f'../Data/ttsOutputs/{model_dir_name}'\n",
    "        os.makedirs(modelDirectory, exist_ok=True)\n",
    "        speakerSentencesPath = f'../Data/ttsOutputs/{model_dir_name}_generatedSentences.json'\n",
    "        speakerSentences = loadGeneratedSentencesFromJson(speakerSentencesPath)\n",
    "\n",
    "        for i in range(0, len(missing_speakers), batch_size):\n",
    "            batch = missing_speakers[i:i + batch_size]\n",
    "            print(f\"Processing batch {i // batch_size + 1}: {batch}\")\n",
    "\n",
    "            tts = generateTTS(model)\n",
    "            if tts is None:\n",
    "                print(f\"Failed to generate TTS for model {model}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            results = []\n",
    "            with ThreadPoolExecutor(max_workers=batch_size) as executor:\n",
    "                futures = [\n",
    "                    executor.submit(process_speaker, speaker, trainDF, tts, modelDirectory)\n",
    "                    for speaker in batch\n",
    "                ]\n",
    "                for future in as_completed(futures):\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        results.append(result)\n",
    "            # Write results after batch\n",
    "            speakerSentences.extend(results)\n",
    "            with open(speakerSentencesPath, 'w') as f:\n",
    "                json.dump(speakerSentences, f)\n",
    "\n",
    "            saveGeneratedSentences(speakerSentences, model_dir_name, modelDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7e707-4a0d-4f85-8a9c-ae9694d4a2e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    trainDF = readCsv('train')\n",
    "    speakers = getSpeakers(trainDF)\n",
    "    if not exists('../Data/concatenatedInputs'):\n",
    "        os.makedirs('../Data/concatenatedInputs')\n",
    "        for speaker in speakers:\n",
    "            speakerDF = getFilesBySpeaker(trainDF, speaker)\n",
    "            concatenateAudio(speaker, speakerDF)\n",
    "    if not exists('../Data/ttsOutputs/'):\n",
    "        os.makedirs('../Data/ttsOutputs/')\n",
    "    \n",
    "    # Process speakers in batches\n",
    "    generateAudioInBatches(speakers, trainDF, batch_size=10)\n",
    "    \n",
    "    print(\"done\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768240ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Name format: type/language/dataset/model\n",
      " 1: tts_models/multilingual/multi-dataset/xtts_v2\n",
      " 2: tts_models/multilingual/multi-dataset/xtts_v1.1\n",
      " 3: tts_models/multilingual/multi-dataset/your_tts\n",
      " 4: tts_models/multilingual/multi-dataset/bark\n",
      " 5: tts_models/bg/cv/vits\n",
      " 6: tts_models/cs/cv/vits\n",
      " 7: tts_models/da/cv/vits\n",
      " 8: tts_models/et/cv/vits\n",
      " 9: tts_models/ga/cv/vits\n",
      " 10: tts_models/en/ek1/tacotron2 [already downloaded]\n",
      " 11: tts_models/en/ljspeech/tacotron2-DDC [already downloaded]\n",
      " 12: tts_models/en/ljspeech/tacotron2-DDC_ph [already downloaded]\n",
      " 13: tts_models/en/ljspeech/glow-tts [already downloaded]\n",
      " 14: tts_models/en/ljspeech/speedy-speech [already downloaded]\n",
      " 15: tts_models/en/ljspeech/tacotron2-DCA [already downloaded]\n",
      " 16: tts_models/en/ljspeech/vits [already downloaded]\n",
      " 17: tts_models/en/ljspeech/vits--neon [already downloaded]\n",
      " 18: tts_models/en/ljspeech/fast_pitch [already downloaded]\n",
      " 19: tts_models/en/ljspeech/overflow [already downloaded]\n",
      " 20: tts_models/en/ljspeech/neural_hmm [already downloaded]\n",
      " 21: tts_models/en/vctk/vits [already downloaded]\n",
      " 22: tts_models/en/vctk/fast_pitch [already downloaded]\n",
      " 23: tts_models/en/sam/tacotron-DDC [already downloaded]\n",
      " 24: tts_models/en/blizzard2013/capacitron-t2-c50 [already downloaded]\n",
      " 25: tts_models/en/blizzard2013/capacitron-t2-c150_v2 [already downloaded]\n",
      " 26: tts_models/en/multi-dataset/tortoise-v2 [already downloaded]\n",
      " 27: tts_models/en/jenny/jenny [already downloaded]\n",
      " 28: tts_models/es/mai/tacotron2-DDC\n",
      " 29: tts_models/es/css10/vits\n",
      " 30: tts_models/fr/mai/tacotron2-DDC\n",
      " 31: tts_models/fr/css10/vits\n",
      " 32: tts_models/uk/mai/glow-tts\n",
      " 33: tts_models/uk/mai/vits\n",
      " 34: tts_models/zh-CN/baker/tacotron2-DDC-GST\n",
      " 35: tts_models/nl/mai/tacotron2-DDC\n",
      " 36: tts_models/nl/css10/vits\n",
      " 37: tts_models/de/thorsten/tacotron2-DCA\n",
      " 38: tts_models/de/thorsten/vits\n",
      " 39: tts_models/de/thorsten/tacotron2-DDC\n",
      " 40: tts_models/de/css10/vits-neon\n",
      " 41: tts_models/ja/kokoro/tacotron2-DDC\n",
      " 42: tts_models/tr/common-voice/glow-tts\n",
      " 43: tts_models/it/mai_female/glow-tts\n",
      " 44: tts_models/it/mai_female/vits\n",
      " 45: tts_models/it/mai_male/glow-tts\n",
      " 46: tts_models/it/mai_male/vits\n",
      " 47: tts_models/ewe/openbible/vits\n",
      " 48: tts_models/hau/openbible/vits\n",
      " 49: tts_models/lin/openbible/vits\n",
      " 50: tts_models/tw_akuapem/openbible/vits\n",
      " 51: tts_models/tw_asante/openbible/vits\n",
      " 52: tts_models/yor/openbible/vits\n",
      " 53: tts_models/hu/css10/vits\n",
      " 54: tts_models/el/cv/vits\n",
      " 55: tts_models/fi/css10/vits\n",
      " 56: tts_models/hr/cv/vits\n",
      " 57: tts_models/lt/cv/vits\n",
      " 58: tts_models/lv/cv/vits\n",
      " 59: tts_models/mt/cv/vits\n",
      " 60: tts_models/pl/mai_female/vits\n",
      " 61: tts_models/pt/cv/vits\n",
      " 62: tts_models/ro/cv/vits\n",
      " 63: tts_models/sk/cv/vits\n",
      " 64: tts_models/sl/cv/vits\n",
      " 65: tts_models/sv/cv/vits\n",
      " 66: tts_models/ca/custom/vits\n",
      " 67: tts_models/fa/custom/glow-tts\n",
      " 68: tts_models/bn/custom/vits-male\n",
      " 69: tts_models/bn/custom/vits-female\n",
      " 70: tts_models/be/common-voice/glow-tts\n",
      "\n",
      " Name format: type/language/dataset/model\n",
      " 1: vocoder_models/universal/libri-tts/wavegrad\n",
      " 2: vocoder_models/universal/libri-tts/fullband-melgan\n",
      " 3: vocoder_models/en/ek1/wavegrad [already downloaded]\n",
      " 4: vocoder_models/en/ljspeech/multiband-melgan [already downloaded]\n",
      " 5: vocoder_models/en/ljspeech/hifigan_v2 [already downloaded]\n",
      " 6: vocoder_models/en/ljspeech/univnet [already downloaded]\n",
      " 7: vocoder_models/en/blizzard2013/hifigan_v2 [already downloaded]\n",
      " 8: vocoder_models/en/vctk/hifigan_v2 [already downloaded]\n",
      " 9: vocoder_models/en/sam/hifigan_v2 [already downloaded]\n",
      " 10: vocoder_models/nl/mai/parallel-wavegan\n",
      " 11: vocoder_models/de/thorsten/wavegrad\n",
      " 12: vocoder_models/de/thorsten/fullband-melgan\n",
      " 13: vocoder_models/de/thorsten/hifigan_v1\n",
      " 14: vocoder_models/ja/kokoro/hifigan_v1\n",
      " 15: vocoder_models/uk/mai/multiband-melgan\n",
      " 16: vocoder_models/tr/common-voice/hifigan\n",
      " 17: vocoder_models/be/common-voice/hifigan\n",
      "\n",
      " Name format: type/language/dataset/model\n",
      " 1: voice_conversion_models/multilingual/vctk/freevc24 [already downloaded]\n",
      "Processing model: tts_models/en/ek1/tacotron2\n",
      "missing 73 speakers for model tts_models/en/ek1/tacotron2\n",
      "Processing batch 1: ['MWEM0', 'MAEB0', 'FMJF0', 'MDLM0', 'MKDT0', 'MJWT0', 'FCYL0', 'MKLR0', 'MPSW0', 'MTLC0']\n",
      " > tts_models/en/ek1/tacotron2 is already downloaded.\n",
      " > vocoder_models/en/ek1/wavegrad is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-10\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.8\n",
      " | > preemphasis:0.99\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: wavegrad\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MKDT0.wav already exists. Skipping.\n",
      "Generating audio for sentence: Vietnamese cuisine is exquisite.\n",
      "Generating audio for sentence: The preschooler couldn't verbalize her feelings about the emergency conditions.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Generating audio for sentence: Trespassing is forbidden and subject to penalty.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Generating audio for sentence: Often you'll get back more than you put in.\n",
      "Generating audio for sentence: Their gait is impossible to convey in words.\n",
      " > Text splitted to sentences.\n",
      "['Vietnamese cuisine is exquisite.']\n",
      " > Text splitted to sentences.\n",
      "['Their gait is impossible to convey in words.']\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      " > Text splitted to sentences.\n",
      "[\"Often you'll get back more than you put in.\"]\n",
      " > Text splitted to sentences.\n",
      "[\"The preschooler couldn't verbalize her feelings about the emergency conditions.\"]\n",
      " > Text splitted to sentences.\n",
      "['Trespassing is forbidden and subject to penalty.']\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: Maybe they're delivering the desk now!\n",
      "Generating audio for sentence: The meeting is now adjourned.\n",
      " > Text splitted to sentences.\n",
      "[\"Maybe they're delivering the desk now!\"]\n",
      " > Text splitted to sentences.\n",
      "['The meeting is now adjourned.']\n",
      "ðə mitɪŋ ɪz naʊ əd͡ʒɚnd.\n",
      " [!] Character '͡' not found in the vocabulary. Discarding it.\n",
      "Failed to generate or normalize audio: The size of tensor a (31) must match the size of tensor b (23) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (31) must match the size of tensor b (23) at non-singleton dimension 1\n",
      "Generating audio for sentence: Vietnamese cuisine is exquisite.\n",
      "Generating audio for sentence: The meeting is now adjourned.\n",
      " > Text splitted to sentences.\n",
      "['Vietnamese cuisine is exquisite.']\n",
      " > Text splitted to sentences.\n",
      "['The meeting is now adjourned.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 31 but got size 45 for tensor number 1 in the list.\n",
      "Generating audio for sentence: Trespassing is forbidden and subject to penalty.\n",
      " > Text splitted to sentences.\n",
      "['Trespassing is forbidden and subject to penalty.']\n",
      "Failed to generate or normalize audio: The size of tensor a (40) must match the size of tensor b (23) at non-singleton dimension 1\n",
      "Generating audio for sentence: Maybe they're delivering the desk now!\n",
      " > Text splitted to sentences.\n",
      "[\"Maybe they're delivering the desk now!\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (36) must match the size of tensor b (40) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (36) must match the size of tensor b (40) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (36) must match the size of tensor b (40) at non-singleton dimension 1\n",
      "Generating audio for sentence: Their gait is impossible to convey in words.\n",
      " > Text splitted to sentences.\n",
      "['Their gait is impossible to convey in words.']\n",
      "Failed to generate or normalize audio: The size of tensor a (67) must match the size of tensor b (36) at non-singleton dimension 1\n",
      "Generating audio for sentence: Often you'll get back more than you put in.\n",
      " > Text splitted to sentences.\n",
      "[\"Often you'll get back more than you put in.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (31) must match the size of tensor b (67) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (31) must match the size of tensor b (67) at non-singleton dimension 1\n",
      "Generating audio for sentence: The preschooler couldn't verbalize her feelings about the emergency conditions.\n",
      " > Text splitted to sentences.\n",
      "[\"The preschooler couldn't verbalize her feelings about the emergency conditions.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (40) must match the size of tensor b (31) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 45 but got size 36 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 45 but got size 36 for tensor number 1 in the list.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 45 but got size 36 for tensor number 1 in the list.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 45 but got size 36 for tensor number 1 in the list.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 67] at entry 0 and [1, 45] at entry 1\n",
      " > Processing time: 18.916303873062134\n",
      " > Real-time factor: 9.201917146157344\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.19 seconds.\n",
      " > Processing time: 20.460187673568726\n",
      " > Real-time factor: 9.62673135460461\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 2: ['MBWP0', 'MARC0', 'MAJP0', 'FKAA0', 'MCSS0', 'MWSH0', 'FALR0', 'FPLS0', 'MMAA0', 'MJLG1']\n",
      " > tts_models/en/ek1/tacotron2 is already downloaded.\n",
      " > vocoder_models/en/ek1/wavegrad is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-10\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.8\n",
      " | > preemphasis:0.99\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: wavegrad\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/FPLS0.wav already exists. Skipping.\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MJLG1.wav already exists. Skipping.\n",
      "Generating audio for sentence: Will you please describe the idiotic predicament.\n",
      "Generating audio for sentence: His scalp was blistered from today's hot sun.\n",
      "Generating audio for sentence: Jeff's toy go-cart never worked!\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "[\"His scalp was blistered from today's hot sun.\"]\n",
      "Generating audio for sentence: She can remove all knick-knacks within reach.\n",
      " > Text splitted to sentences.\n",
      "['Will you please describe the idiotic predicament.']\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She can remove all knick-knacks within reach.']\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Jeff's toy go-cart never worked!\"]\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "d͡ʒɛfs tɔɪ ɡoʊ kɑɹt nɛvɚ wɚkt!\n",
      " [!] Character '͡' not found in the vocabulary. Discarding it.\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Generating audio for sentence: Will you please describe the idiotic predicament.\n",
      " > Text splitted to sentences.\n",
      "['Will you please describe the idiotic predicament.']\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 42] at entry 0 and [1, 45] at entry 1\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (42) at non-singleton dimension 1\n",
      "Generating audio for sentence: His scalp was blistered from today's hot sun.\n",
      "Generating audio for sentence: She can remove all knick-knacks within reach.\n",
      " > Text splitted to sentences.\n",
      "[\"His scalp was blistered from today's hot sun.\"]\n",
      " > Text splitted to sentences.\n",
      "['She can remove all knick-knacks within reach.']\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Failed to generate or normalize audio: The size of tensor a (36) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (36) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (36) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: Jeff's toy go-cart never worked!\n",
      " > Text splitted to sentences.\n",
      "[\"Jeff's toy go-cart never worked!\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (36) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (36) at non-singleton dimension 1\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (29) at non-singleton dimension 1\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (29) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (42) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 45] at entry 0 and [1, 42] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 42] at entry 0 and [1, 45] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 42] at entry 0 and [1, 45] at entry 2\n",
      " > Processing time: 111.06462717056274\n",
      " > Real-time factor: 8.0997480721507\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 3: ['FKLH0', 'MSMC0', 'MZMB0', 'FKSR0', 'MCAE0', 'FDML0', 'MDWD0', 'FGRW0', 'MJAE0', 'MJFR0']\n",
      " > tts_models/en/ek1/tacotron2 is already downloaded.\n",
      " > vocoder_models/en/ek1/wavegrad is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-10\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.8\n",
      " | > preemphasis:0.99\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: wavegrad\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MSMC0.wav already exists. Skipping.\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/FKSR0.wav already exists. Skipping.\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MJAE0.wav already exists. Skipping.\n",
      "Generating audio for sentence: Draw every outer line first, then fill in the interior.\n",
      "Generating audio for sentence: Withdraw only as much money as you need.\n",
      "Generating audio for sentence: The surplus shoes were sold at a discount price.\n",
      "Generating audio for sentence: Did Shawn catch that big goose without help?\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MJFR0.wav already exists. Skipping.\n",
      "Generating audio for sentence: Are holiday aprons available to us?\n",
      " > Text splitted to sentences.\n",
      "['Draw every outer line first, then fill in the interior.']\n",
      " > Text splitted to sentences.\n",
      "['Withdraw only as much money as you need.']\n",
      " > Text splitted to sentences.\n",
      "['The surplus shoes were sold at a discount price.']\n",
      " > Text splitted to sentences.\n",
      "['Are holiday aprons available to us?']\n",
      " > Text splitted to sentences.\n",
      "['Did Shawn catch that big goose without help?']\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "wɪθdɹɔ oʊnli æz mʌt͡ʃ mʌni æz ju nid.\n",
      " [!] Character '͡' not found in the vocabulary. Discarding it.\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 35] at entry 0 and [1, 36] at entry 1\n",
      "Generating audio for sentence: Are holiday aprons available to us?\n",
      " > Text splitted to sentences.\n",
      "['Are holiday aprons available to us?']\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 36] at entry 0 and [1, 37] at entry 1\n",
      "Generating audio for sentence: Withdraw only as much money as you need.\n",
      " > Text splitted to sentences.\n",
      "['Withdraw only as much money as you need.']\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 37] at entry 0 and [1, 36] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 37] at entry 0 and [1, 36] at entry 1\n",
      "Generating audio for sentence: The surplus shoes were sold at a discount price.\n",
      " > Text splitted to sentences.\n",
      "['The surplus shoes were sold at a discount price.']\n",
      "Generating audio for sentence: Did Shawn catch that big goose without help?\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (36) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['Did Shawn catch that big goose without help?']\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (36) at non-singleton dimension 1\n",
      "Generating audio for sentence: Draw every outer line first, then fill in the interior.\n",
      " > Text splitted to sentences.\n",
      "['Draw every outer line first, then fill in the interior.']\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 42] at entry 0 and [1, 37] at entry 1\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 37] at entry 0 and [1, 42] at entry 1\n",
      "Failed to generate or normalize audio: The size of tensor a (43) must match the size of tensor b (37) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 37 but got size 43 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 37 but got size 43 for tensor number 1 in the list.\n",
      " > Processing time: 18.15838313102722\n",
      " > Real-time factor: 6.229654406882472\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 4: ['MJDM0', nan, 'FNKL0', 'FJSK0', 'MGAK0', 'MHRM0', 'FSRH0', 'MWRE0', 'FMBG0', 'FJXM0']\n",
      " > tts_models/en/ek1/tacotron2 is already downloaded.\n",
      " > vocoder_models/en/ek1/wavegrad is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-10\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.8\n",
      " | > preemphasis:0.99\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: wavegrad\n",
      "No data for speaker nan. Skipping.\n",
      "Generating audio for sentence: The social and psychological consequences of this continue to affect the area.\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/FJXM0.wav already exists. Skipping.\n",
      " > Text splitted to sentences.\n",
      "['The social and psychological consequences of this continue to affect the area.']\n",
      "Generating audio for sentence: The shock therapies act likewise on the hypothalamic balance.\n",
      "Generating audio for sentence: No chemical fertilizers and poisonous insecticides and fungicides are used.\n",
      " > Text splitted to sentences.\n",
      "['The shock therapies act likewise on the hypothalamic balance.']\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['No chemical fertilizers and poisonous insecticides and fungicides are used.']\n",
      "Generating audio for sentence: That pickpocket was caught red-handed.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: We experience distress and frustration obtaining our degrees.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['That pickpocket was caught red-handed.']\n",
      "Generating audio for sentence: Now don't shut this door.\n",
      " > Text splitted to sentences.\n",
      "['We experience distress and frustration obtaining our degrees.']\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      " > Text splitted to sentences.\n",
      "[\"Now don't shut this door.\"]\n",
      "noʊ kɛmɪkəl fɚtɪlaɪzɚz ænd pɔɪzənəs ɪnsɛktɪsaɪdz ænd fʌnd͡ʒɪsaɪdz ɑɹ just.\n",
      " [!] Character '͡' not found in the vocabulary. Discarding it.\n",
      "Failed to generate or normalize audio: The size of tensor a (55) must match the size of tensor b (32) at non-singleton dimension 1\n",
      "Generating audio for sentence: That pickpocket was caught red-handed.\n",
      "Failed to generate or normalize audio: The size of tensor a (58) must match the size of tensor b (32) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['That pickpocket was caught red-handed.']\n",
      "Generating audio for sentence: Now don't shut this door.\n",
      " > Text splitted to sentences.\n",
      "[\"Now don't shut this door.\"]\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 73 but got size 32 for tensor number 1 in the list.\n",
      "Generating audio for sentence: We experience distress and frustration obtaining our degrees.\n",
      " > Text splitted to sentences.\n",
      "['We experience distress and frustration obtaining our degrees.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 73 but got size 32 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 73 but got size 32 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 73 but got size 32 for tensor number 1 in the list.\n",
      "Generating audio for sentence: No chemical fertilizers and poisonous insecticides and fungicides are used.\n",
      "Generating audio for sentence: The shock therapies act likewise on the hypothalamic balance.\n",
      " > Text splitted to sentences.\n",
      "['No chemical fertilizers and poisonous insecticides and fungicides are used.']\n",
      " > Text splitted to sentences.\n",
      "['The shock therapies act likewise on the hypothalamic balance.']\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (58) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 58] at entry 0 and [1, 73] at entry 1\n",
      " > Processing time: 34.582396030426025\n",
      " > Real-time factor: 13.722679104356713\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "   > Decoder stopped with `max_decoder_steps` 10000\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 45] at entry 0 and [1, 73] at entry 1\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 58] at entry 0 and [1, 73] at entry 1\n",
      "   > Decoder stopped with `max_decoder_steps` 10000\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 73] at entry 0 and [1, 45] at entry 9990\n",
      "Generating audio for sentence: The social and psychological consequences of this continue to affect the area.\n",
      " > Text splitted to sentences.\n",
      "['The social and psychological consequences of this continue to affect the area.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 45 but got size 74 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 45 but got size 74 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 45 but got size 74 for tensor number 1 in the list.\n",
      "Processing batch 5: ['FCKE0', 'MTBC0', 'MTRR0', 'MFRM0', 'FMKF0', 'MCEF0', 'MRLJ1', 'MRFK0', 'MSFH0', 'MDKS0']\n",
      " > tts_models/en/ek1/tacotron2 is already downloaded.\n",
      " > vocoder_models/en/ek1/wavegrad is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-10\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.8\n",
      " | > preemphasis:0.99\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: wavegrad\n",
      "Generating audio for sentence: They all like long hot showers.\n",
      "Generating audio for sentence: Very peculiar retribution indeed seems to overtake such jokers.\n",
      " > Text splitted to sentences.\n",
      "['They all like long hot showers.']\n",
      "Generating audio for sentence: Trish saw hours and hours of movies Saturday.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Generating audio for sentence: Would you please confirm government policy regarding waste removal?\n",
      "Generating audio for sentence: The cow wandered from the farmland and became lost.\n",
      " > Text splitted to sentences.\n",
      "['Trish saw hours and hours of movies Saturday.']\n",
      " > Text splitted to sentences.\n",
      "['Very peculiar retribution indeed seems to overtake such jokers.']\n",
      "Generating audio for sentence: There was a gigantic wasp next to Irving's big top hat.\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      " > Text splitted to sentences.\n",
      "[\"There was a gigantic wasp next to Irving's big top hat.\"]\n",
      " > Text splitted to sentences.\n",
      "['Would you please confirm government policy regarding waste removal?']\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "['The cow wandered from the farmland and became lost.']\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: The irate actor stomped away idiotically.\n",
      " > Text splitted to sentences.\n",
      "['The irate actor stomped away idiotically.']\n",
      "vɛɹi pɪkjuljɚ ɹɛtɹɪbjuʃən ɪndid simz tə oʊvɚteɪk sʌt͡ʃ d͡ʒoʊkɚz.\n",
      " [!] Character '͡' not found in the vocabulary. Discarding it.\n",
      "Failed to generate or normalize audio: The size of tensor a (37) must match the size of tensor b (26) at non-singleton dimension 1\n",
      "Generating audio for sentence: They all like long hot showers.\n",
      " > Text splitted to sentences.\n",
      "['They all like long hot showers.']\n",
      "Failed to generate or normalize audio: The size of tensor a (62) must match the size of tensor b (26) at non-singleton dimension 1\n",
      "Generating audio for sentence: Trish saw hours and hours of movies Saturday.\n",
      " > Text splitted to sentences.\n",
      "['Trish saw hours and hours of movies Saturday.']\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (62) at non-singleton dimension 1\n",
      "Generating audio for sentence: Very peculiar retribution indeed seems to overtake such jokers.\n",
      " > Text splitted to sentences.\n",
      "['Very peculiar retribution indeed seems to overtake such jokers.']\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 47] at entry 0 and [1, 45] at entry 1\n",
      "Generating audio for sentence: The irate actor stomped away idiotically.\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (62) at non-singleton dimension 1\n",
      "Generating audio for sentence: Would you please confirm government policy regarding waste removal?\n",
      " > Text splitted to sentences.\n",
      "['The irate actor stomped away idiotically.']\n",
      " > Text splitted to sentences.\n",
      "['Would you please confirm government policy regarding waste removal?']\n",
      "Failed to generate or normalize audio: The size of tensor a (53) must match the size of tensor b (39) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (53) must match the size of tensor b (39) at non-singleton dimension 1\n",
      "Generating audio for sentence: The cow wandered from the farmland and became lost.\n",
      " > Text splitted to sentences.\n",
      "['The cow wandered from the farmland and became lost.']\n",
      "Failed to generate or normalize audio: The size of tensor a (62) must match the size of tensor b (39) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (62) must match the size of tensor b (37) at non-singleton dimension 1\n",
      "Generating audio for sentence: There was a gigantic wasp next to Irving's big top hat.\n",
      "Failed to generate or normalize audio: Expected size for first two dimensions of batch2 tensor to be: [1, 39] but got: [1, 53].\n",
      " > Text splitted to sentences.\n",
      "[\"There was a gigantic wasp next to Irving's big top hat.\"]\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Failed to generate or normalize audio: The size of tensor a (59) must match the size of tensor b (62) at non-singleton dimension 1\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Failed to generate or normalize audio: The size of tensor a (59) must match the size of tensor b (62) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (59) must match the size of tensor b (62) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (59) must match the size of tensor b (62) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (47) must match the size of tensor b (59) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 45] at entry 0 and [1, 53] at entry 1\n",
      " > Processing time: 16.406798839569092\n",
      " > Real-time factor: 10.620300446585793\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 16.697793006896973\n",
      " > Real-time factor: 10.195678328591002\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 16.780109167099\n",
      " > Real-time factor: 10.245940605187554\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 6: ['MADC0', 'FMEM0', 'MHBS0', 'MBML0', 'MRMS0', 'MTLB0', 'MDLC0', 'FETB0', 'MRGM0', 'MREW1']\n",
      " > tts_models/en/ek1/tacotron2 is already downloaded.\n",
      " > vocoder_models/en/ek1/wavegrad is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-10\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.8\n",
      " | > preemphasis:0.99\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: wavegrad\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MBML0.wav already exists. Skipping.\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MTLB0.wav already exists. Skipping.\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MRMS0.wav already exists. Skipping.\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MREW1.wav already exists. Skipping.\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Generating audio for sentence: Bob found more clams at the ocean's edge.\n",
      " > Text splitted to sentences.\n",
      "[\"Bob found more clams at the ocean's edge.\"]\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Generating audio for sentence: Bob found more clams at the ocean's edge.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "[\"Bob found more clams at the ocean's edge.\"]\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: Women didn't use white face powder nowadays, he recalled.\n",
      "Generating audio for sentence: A huge power outage rarely occurs.\n",
      " > Text splitted to sentences.\n",
      "['A huge power outage rarely occurs.']\n",
      " > Text splitted to sentences.\n",
      "[\"Women didn't use white face powder nowadays, he recalled.\"]\n",
      "ə hjud͡ʒ paʊɚ aʊtɪd͡ʒ ɹɛɹli əkɚz.\n",
      " [!] Character '͡' not found in the vocabulary. Discarding it.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 37 but got size 53 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 37 but got size 53 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 37 but got size 53 for tensor number 1 in the list.\n",
      "Generating audio for sentence: Bob found more clams at the ocean's edge.\n",
      "Generating audio for sentence: A huge power outage rarely occurs.\n",
      "Generating audio for sentence: Women didn't use white face powder nowadays, he recalled.\n",
      " > Text splitted to sentences.\n",
      "[\"Bob found more clams at the ocean's edge.\"]\n",
      " > Text splitted to sentences.\n",
      "[\"Women didn't use white face powder nowadays, he recalled.\"]\n",
      " > Text splitted to sentences.\n",
      "['A huge power outage rarely occurs.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 37 but got size 53 for tensor number 1 in the list.\n",
      "Generating audio for sentence: Bob found more clams at the ocean's edge.\n",
      " > Text splitted to sentences.\n",
      "[\"Bob found more clams at the ocean's edge.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (37) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 53] at entry 0 and [1, 45] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 37] at entry 0 and [1, 53] at entry 1\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Processing time: 22.250603199005127\n",
      " > Real-time factor: 13.211595232067618\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 22.50642204284668\n",
      " > Real-time factor: 13.363491114949625\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 23.050234079360962\n",
      " > Real-time factor: 13.500256625847566\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Processing time: 33.09829020500183\n",
      " > Real-time factor: 11.355135969322417\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 7: ['MTXS0', 'FHXS0', 'MPRB0', 'MDLB0', 'MEWM0', 'FHLM0', 'MSES0', 'MVRW0', 'MREE0', 'MMDM1']\n",
      " > tts_models/en/ek1/tacotron2 is already downloaded.\n",
      " > vocoder_models/en/ek1/wavegrad is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-10\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.8\n",
      " | > preemphasis:0.99\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: wavegrad\n",
      "Generating audio for sentence: What is this large thing by the ironing board?Generating audio for sentence: Ducks have webbed feet and colorful feathers.\n",
      "\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MVRW0.wav already exists. Skipping.\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MREE0.wav already exists. Skipping.\n",
      " > Text splitted to sentences.\n",
      "['Ducks have webbed feet and colorful feathers.']\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['What is this large thing by the ironing board?']\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Generating audio for sentence: Theocracy reconsidered.\n",
      "Generating audio for sentence: The coyote, bobcat, and hyena are wild animals.\n",
      "Generating audio for sentence: Chip postponed alimony payments until the latest possible date.\n",
      " > Text splitted to sentences.\n",
      "['Theocracy reconsidered.']\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "['The coyote, bobcat, and hyena are wild animals.']\n",
      " > Text splitted to sentences.\n",
      "['Chip postponed alimony payments until the latest possible date.']\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "wʌt ɪz ðɪs lɑɹd͡ʒ θɪŋ baɪ ðə aɪɚnɪŋ bɔɹd?\n",
      " [!] Character '͡' not found in the vocabulary. Discarding it.\n",
      "Failed to generate or normalize audio: The size of tensor a (40) must match the size of tensor b (48) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (40) must match the size of tensor b (48) at non-singleton dimension 1\n",
      "Generating audio for sentence: Ducks have webbed feet and colorful feathers.\n",
      " > Text splitted to sentences.\n",
      "['Ducks have webbed feet and colorful feathers.']\n",
      "Generating audio for sentence: Theocracy reconsidered.\n",
      " > Text splitted to sentences.\n",
      "['Theocracy reconsidered.']\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (40) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (40) at non-singleton dimension 1\n",
      "Generating audio for sentence: Chip postponed alimony payments until the latest possible date.\n",
      "Generating audio for sentence: What is this large thing by the ironing board?\n",
      " > Text splitted to sentences.\n",
      "['Chip postponed alimony payments until the latest possible date.']\n",
      " > Text splitted to sentences.\n",
      "['What is this large thing by the ironing board?']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 40 but got size 45 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 40 but got size 45 for tensor number 1 in the list.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 20] at entry 0 and [1, 64] at entry 1\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (64) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (64) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (64) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (64) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (64) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (64) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: The coyote, bobcat, and hyena are wild animals.\n",
      " > Text splitted to sentences.\n",
      "['The coyote, bobcat, and hyena are wild animals.']\n",
      " > Processing time: 37.2066810131073\n",
      " > Real-time factor: 9.85876894273957\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 37.4671790599823\n",
      " > Real-time factor: 9.927793913100963\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 8: ['MJRA0', 'MCTH0', 'MMGG0']\n",
      " > tts_models/en/ek1/tacotron2 is already downloaded.\n",
      " > vocoder_models/en/ek1/wavegrad is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-10\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.8\n",
      " | > preemphasis:0.99\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: wavegrad\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ek1_tacotron2/MCTH0.wav already exists. Skipping.\n",
      "Generating audio for sentence: Gosh, the house does look like a morgue, though.\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "['Gosh, the house does look like a morgue, though.']\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Processing time: 23.55669093132019\n",
      " > Real-time factor: 8.935883481895305\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 23.744980812072754\n",
      " > Real-time factor: 8.92866348748643\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing model: tts_models/en/ljspeech/tacotron2-DDC\n",
      "missing 369 speakers for model tts_models/en/ljspeech/tacotron2-DDC\n",
      "Processing batch 1: ['FECD0', 'MKLN0', 'MGRP0', 'MLBC0', 'MSMS0', 'FCLT0', 'FSKC0', 'MTJM0', 'FBLV0', 'MPRT0']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: The drunkard is a social outcast.\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Generating audio for sentence: We don't know this guy.\n",
      " > Text splitted to sentences.\n",
      "['The drunkard is a social outcast.']\n",
      "Generating audio for sentence: Thus far the advances made have been almost entirely along functional lines.\n",
      "Generating audio for sentence: A connoisseur will enjoy this shellfish dish.\n",
      "Generating audio for sentence: The drunkard is a social outcast.\n",
      " > Text splitted to sentences.\n",
      "[\"We don't know this guy.\"]\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "['A connoisseur will enjoy this shellfish dish.']\n",
      " > Text splitted to sentences.\n",
      "['The drunkard is a social outcast.']\n",
      "Generating audio for sentence: Necessary retouching was put on at once.\n",
      " > Text splitted to sentences.\n",
      "['Thus far the advances made have been almost entirely along functional lines.']\n",
      "Generating audio for sentence: Cyclical programs will never compile.\n",
      " > Text splitted to sentences.\n",
      "['Necessary retouching was put on at once.']\n",
      "Generating audio for sentence: Just drop notices in any suggestion box.\n",
      " > Text splitted to sentences.\n",
      "['Cyclical programs will never compile.']\n",
      " > Text splitted to sentences.\n",
      "['Just drop notices in any suggestion box.']\n",
      "Generating audio for sentence: Something else distracted him, yet there was no sound, only tomblike silence.\n",
      " > Text splitted to sentences.\n",
      "['Something else distracted him, yet there was no sound, only tomblike silence.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 37 but got size 40 for tensor number 1 in the list.\n",
      "Generating audio for sentence: The drunkard is a social outcast.\n",
      " > Text splitted to sentences.\n",
      "['The drunkard is a social outcast.']\n",
      "Failed to generate or normalize audio: The size of tensor a (76) must match the size of tensor b (40) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (76) must match the size of tensor b (37) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (76) must match the size of tensor b (37) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (76) must match the size of tensor b (37) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (76) must match the size of tensor b (40) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (76) must match the size of tensor b (37) at non-singleton dimension 1\n",
      "Generating audio for sentence: A connoisseur will enjoy this shellfish dish.\n",
      "Generating audio for sentence: We don't know this guy.\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Generating audio for sentence: Necessary retouching was put on at once.\n",
      "Generating audio for sentence: Just drop notices in any suggestion box.\n",
      "Generating audio for sentence: The drunkard is a social outcast.\n",
      " > Text splitted to sentences.\n",
      "[\"We don't know this guy.\"]\n",
      " > Text splitted to sentences.\n",
      "['A connoisseur will enjoy this shellfish dish.']\n",
      " > Text splitted to sentences.\n",
      "['Necessary retouching was put on at once.']\n",
      " > Text splitted to sentences.\n",
      "['The drunkard is a social outcast.']\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "['Just drop notices in any suggestion box.']\n",
      "Failed to generate or normalize audio: The size of tensor a (77) must match the size of tensor b (76) at non-singleton dimension 1\n",
      "Generating audio for sentence: Cyclical programs will never compile.\n",
      "Failed to generate or normalize audio: The size of tensor a (76) must match the size of tensor b (77) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['Cyclical programs will never compile.']\n",
      "Generating audio for sentence: Thus far the advances made have been almost entirely along functional lines.\n",
      " > Text splitted to sentences.\n",
      "['Thus far the advances made have been almost entirely along functional lines.']\n",
      "Failed to generate or normalize audio: The size of tensor a (40) must match the size of tensor b (33) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (40) must match the size of tensor b (33) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 40 but got size 37 for tensor number 1 in the list.\n",
      "Generating audio for sentence: Something else distracted him, yet there was no sound, only tomblike silence.\n",
      "Failed to generate or normalize audio: The size of tensor a (37) must match the size of tensor b (44) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['Something else distracted him, yet there was no sound, only tomblike silence.']\n",
      "Failed to generate or normalize audio: The size of tensor a (76) must match the size of tensor b (37) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (76) must match the size of tensor b (37) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (76) must match the size of tensor b (37) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 76] at entry 0 and [1, 77] at entry 3\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 76] at entry 0 and [1, 77] at entry 2\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 76] at entry 0 and [1, 77] at entry 3\n",
      " > Processing time: 1.572242021560669\n",
      " > Real-time factor: 0.44684389275382486\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 2: ['MCRE0', 'MGJC0', 'MBJV0', 'MVLO0', 'FKAA0', 'FAPB0', 'MMBS0', 'MWSH0', 'MTJU0', 'MJLG1']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Generating audio for sentence: The lady's eyes, unmagnified, bugged out.\n",
      "Generating audio for sentence: Bagpipes and bongos are musical instruments.\n",
      "Generating audio for sentence: Although always alone, we survive.\n",
      "Generating audio for sentence: My ideal morning begins with hot coffee.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Generating audio for sentence: It was awkward: very awkward.\n",
      " > Text splitted to sentences.\n",
      "[\"The lady's eyes, unmagnified, bugged out.\"]\n",
      "Generating audio for sentence: His manhood had been attacked.\n",
      "Generating audio for sentence: Stimulating discussions keep students' attention.\n",
      " > Text splitted to sentences.\n",
      "['Bagpipes and bongos are musical instruments.']\n",
      "Generating audio for sentence: The fifth jar contains big, juicy peaches.\n",
      "Generating audio for sentence: George is paranoid about a future gas shortage.\n",
      " > Text splitted to sentences.\n",
      "['My ideal morning begins with hot coffee.']\n",
      " > Text splitted to sentences.\n",
      "['Although always alone, we survive.']\n",
      " > Text splitted to sentences.\n",
      "['The fifth jar contains big, juicy peaches.']\n",
      " > Text splitted to sentences.\n",
      "['His manhood had been attacked.']\n",
      " > Text splitted to sentences.\n",
      "['George is paranoid about a future gas shortage.']\n",
      " > Text splitted to sentences.\n",
      "[\"Stimulating discussions keep students' attention.\"]\n",
      " > Text splitted to sentences.\n",
      "['It was awkward: very awkward.']\n",
      "Failed to generate or normalize audio: The size of tensor a (34) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (40) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Generating audio for sentence: The lady's eyes, unmagnified, bugged out.\n",
      " > Text splitted to sentences.\n",
      "[\"The lady's eyes, unmagnified, bugged out.\"]\n",
      "Generating audio for sentence: His manhood had been attacked.\n",
      " > Text splitted to sentences.\n",
      "['His manhood had been attacked.']\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (42) at non-singleton dimension 1\n",
      "Generating audio for sentence: It was awkward: very awkward.\n",
      " > Text splitted to sentences.\n",
      "['It was awkward: very awkward.']\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (49) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (49) at non-singleton dimension 1\n",
      "Generating audio for sentence: Stimulating discussions keep students' attention.\n",
      " > Text splitted to sentences.\n",
      "[\"Stimulating discussions keep students' attention.\"]\n",
      "Generating audio for sentence: My ideal morning begins with hot coffee.\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (49) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (49) at non-singleton dimension 1\n",
      "Generating audio for sentence: The fifth jar contains big, juicy peaches.\n",
      " > Text splitted to sentences.\n",
      "['The fifth jar contains big, juicy peaches.']\n",
      " > Text splitted to sentences.\n",
      "['My ideal morning begins with hot coffee.']\n",
      "Generating audio for sentence: Bagpipes and bongos are musical instruments.\n",
      " > Text splitted to sentences.\n",
      "['Bagpipes and bongos are musical instruments.']\n",
      "Failed to generate or normalize audio: The size of tensor a (41) must match the size of tensor b (30) at non-singleton dimension 1\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 29 but got size 41 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 29 but got size 41 for tensor number 1 in the list.\n",
      "Generating audio for sentence: Although always alone, we survive.\n",
      " > Text splitted to sentences.\n",
      "['Although always alone, we survive.']\n",
      "Failed to generate or normalize audio: The size of tensor a (49) must match the size of tensor b (29) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (49) must match the size of tensor b (29) at non-singleton dimension 1\n",
      "Generating audio for sentence: George is paranoid about a future gas shortage.\n",
      " > Text splitted to sentences.\n",
      "['George is paranoid about a future gas shortage.']\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (49) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (49) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (40) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 40 but got size 44 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Expected size for first two dimensions of batch2 tensor to be: [1, 47] but got: [1, 44].\n",
      "Failed to generate or normalize audio: Expected size for first two dimensions of batch2 tensor to be: [1, 47] but got: [1, 44].\n",
      "Failed to generate or normalize audio: Expected size for first two dimensions of batch2 tensor to be: [1, 47] but got: [1, 44].\n",
      "Failed to generate or normalize audio: Expected size for first two dimensions of batch2 tensor to be: [1, 47] but got: [1, 44].\n",
      "Processing batch 3: ['FDFB0', 'MPMB0', 'MTQC0', 'MMAR0', 'MNET0', 'FJXM0', 'MDMA0', 'FBAS0', 'FMAH1', 'MRDM0']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: Other morphological, physical, and optical property values are also given.\n",
      "Generating audio for sentence: Biologists use radioactive isotopes to study microorganisms.\n",
      "Generating audio for sentence: The cloudburst cut off abruptly.\n",
      "Generating audio for sentence: Bright sunshine shimmers on the ocean.\n",
      "Generating audio for sentence: We plan to build a new beverage plant.\n",
      " > Text splitted to sentences.\n",
      "['Other morphological, physical, and optical property values are also given.']\n",
      " > Text splitted to sentences.\n",
      "['Biologists use radioactive isotopes to study microorganisms.']\n",
      "Generating audio for sentence: Those who teach values first abolish cheating.\n",
      "Generating audio for sentence: I ate every oyster on Nora's plate.\n",
      " > Text splitted to sentences.\n",
      "['The cloudburst cut off abruptly.']\n",
      " > Text splitted to sentences.\n",
      "['We plan to build a new beverage plant.']\n",
      " > Text splitted to sentences.\n",
      "[\"I ate every oyster on Nora's plate.\"]\n",
      "Generating audio for sentence: The Mayan neoclassic scholar disappeared while surveying ancient ruins.\n",
      "Generating audio for sentence: The meeting is now adjourned.\n",
      " > Text splitted to sentences.\n",
      "['Bright sunshine shimmers on the ocean.']\n",
      " > Text splitted to sentences.\n",
      "['Those who teach values first abolish cheating.']\n",
      " > Text splitted to sentences.\n",
      "['The meeting is now adjourned.']\n",
      " > Text splitted to sentences.\n",
      "['The Mayan neoclassic scholar disappeared while surveying ancient ruins.']\n",
      "Generating audio for sentence: A tsunami is not a single wave but a series.\n",
      " > Text splitted to sentences.\n",
      "['A tsunami is not a single wave but a series.']\n",
      "Failed to generate or normalize audio: The size of tensor a (38) must match the size of tensor b (32) at non-singleton dimension 1\n",
      "Generating audio for sentence: The cloudburst cut off abruptly.\n",
      " > Text splitted to sentences.\n",
      "['The cloudburst cut off abruptly.']\n",
      "Failed to generate or normalize audio: The size of tensor a (35) must match the size of tensor b (46) at non-singleton dimension 1\n",
      "Generating audio for sentence: The meeting is now adjourned.\n",
      "Failed to generate or normalize audio: The size of tensor a (35) must match the size of tensor b (46) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['The meeting is now adjourned.']\n",
      "Generating audio for sentence: We plan to build a new beverage plant.\n",
      " > Text splitted to sentences.\n",
      "['We plan to build a new beverage plant.']\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (35) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (35) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (35) at non-singleton dimension 1\n",
      "Generating audio for sentence: Bright sunshine shimmers on the ocean.\n",
      "Generating audio for sentence: Those who teach values first abolish cheating.\n",
      " > Text splitted to sentences.\n",
      "['Bright sunshine shimmers on the ocean.']\n",
      "Generating audio for sentence: I ate every oyster on Nora's plate.\n",
      " > Text splitted to sentences.\n",
      "['Those who teach values first abolish cheating.']\n",
      " > Text splitted to sentences.\n",
      "[\"I ate every oyster on Nora's plate.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (71) must match the size of tensor b (32) at non-singleton dimension 1\n",
      "Generating audio for sentence: Biologists use radioactive isotopes to study microorganisms.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 71 but got size 32 for tensor number 1 in the list.\n",
      "Generating audio for sentence: Other morphological, physical, and optical property values are also given.\n",
      " > Text splitted to sentences.\n",
      "['Biologists use radioactive isotopes to study microorganisms.']\n",
      " > Text splitted to sentences.\n",
      "['Other morphological, physical, and optical property values are also given.']\n",
      "Failed to generate or normalize audio: The size of tensor a (29) must match the size of tensor b (32) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (29) must match the size of tensor b (32) at non-singleton dimension 1\n",
      "Generating audio for sentence: A tsunami is not a single wave but a series.\n",
      " > Text splitted to sentences.\n",
      "['A tsunami is not a single wave but a series.']\n",
      "Failed to generate or normalize audio: The size of tensor a (29) must match the size of tensor b (32) at non-singleton dimension 1\n",
      "Generating audio for sentence: The Mayan neoclassic scholar disappeared while surveying ancient ruins.\n",
      " > Text splitted to sentences.\n",
      "['The Mayan neoclassic scholar disappeared while surveying ancient ruins.']\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (46) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (60) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (60) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (74) must match the size of tensor b (60) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 60 but got size 74 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: The size of tensor a (74) must match the size of tensor b (60) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 44] at entry 0 and [1, 74] at entry 1\n",
      " > Processing time: 1.4458580017089844\n",
      " > Real-time factor: 0.39154510878467164\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 1.4582641124725342\n",
      " > Real-time factor: 0.3936670381980825\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 4: ['MDJM0', 'MLSH0', 'MGAR0', 'MRGM0', 'MBTH0', 'MSEM1', 'MKAJ0', 'FHLM0', 'MSES0', 'FLAC0']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ljspeech_tacotron2-DDC/MLSH0.wav already exists. Skipping.\n",
      "Generating audio for sentence: A third volume remains to be published.\n",
      "Generating audio for sentence: Growing well-kept gardens is very time consuming.\n",
      "Generating audio for sentence: Further, it has its work cut out stopping anarchy where it is now garrisoned.\n",
      " > Text splitted to sentences.\n",
      "['A third volume remains to be published.']\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "['Growing well-kept gardens is very time consuming.']\n",
      "Generating audio for sentence: A young mouse scampered across the field and disappeared.\n",
      " > Text splitted to sentences.\n",
      "['Further, it has its work cut out stopping anarchy where it is now garrisoned.']\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "['A young mouse scampered across the field and disappeared.']\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Generating audio for sentence: The misprint provoked an immediate disclaimer.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "['The misprint provoked an immediate disclaimer.']\n",
      "Failed to generate or normalize audio: The size of tensor a (46) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Failed to generate or normalize audio: The size of tensor a (46) must match the size of tensor b (44) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 57 but got size 46 for tensor number 1 in the list.\n",
      "Generating audio for sentence: The misprint provoked an immediate disclaimer.\n",
      " > Text splitted to sentences.\n",
      "['The misprint provoked an immediate disclaimer.']\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (57) at non-singleton dimension 1\n",
      "Generating audio for sentence: Further, it has its work cut out stopping anarchy where it is now garrisoned.\n",
      " > Text splitted to sentences.\n",
      "['Further, it has its work cut out stopping anarchy where it is now garrisoned.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 53 but got size 46 for tensor number 1 in the list.\n",
      "Generating audio for sentence: Growing well-kept gardens is very time consuming.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 53 but got size 46 for tensor number 1 in the list.\n",
      "Generating audio for sentence: A young mouse scampered across the field and disappeared.\n",
      " > Text splitted to sentences.\n",
      "['Growing well-kept gardens is very time consuming.']\n",
      " > Text splitted to sentences.\n",
      "['A young mouse scampered across the field and disappeared.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 53 but got size 46 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 53 but got size 46 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 53 but got size 46 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 53 but got size 46 for tensor number 1 in the list.\n",
      "Generating audio for sentence: A third volume remains to be published.\n",
      " > Text splitted to sentences.\n",
      "['A third volume remains to be published.']\n",
      "Failed to generate or normalize audio: The size of tensor a (49) must match the size of tensor b (57) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (49) must match the size of tensor b (39) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (49) must match the size of tensor b (39) at non-singleton dimension 1\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Failed to generate or normalize audio: The size of tensor a (49) must match the size of tensor b (39) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (49) must match the size of tensor b (39) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (49) must match the size of tensor b (39) at non-singleton dimension 1\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 53] at entry 0 and [1, 44] at entry 1\n",
      " > Processing time: 4.348952054977417\n",
      " > Real-time factor: 0.347463595035408\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 5: ['MCLM0', 'MPRK0', 'MPEB0', 'MRLK0', 'MRCW0', 'MMGG0', 'FMJF0', 'MJFH0', 'MDEF0', 'FSCN0']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: Check the overnighters out.\n",
      "Generating audio for sentence: We're not drunkards, she said.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Generating audio for sentence: A roll of wire lay near the wall.\n",
      "Generating audio for sentence: It's hard to tell an original from a forgery.\n",
      " > Text splitted to sentences.\n",
      "['Check the overnighters out.']\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      " > Text splitted to sentences.\n",
      "[\"We're not drunkards, she said.\"]\n",
      "Generating audio for sentence: A screwdriver is made from vodka and orange juice.\n",
      " > Text splitted to sentences.\n",
      "[\"It's hard to tell an original from a forgery.\"]\n",
      "Generating audio for sentence: We saw eight tiny icicles below our roof.\n",
      "Generating audio for sentence: Brain examined for thrombosis, clot or hemorrhage.\n",
      " > Text splitted to sentences.\n",
      "['A screwdriver is made from vodka and orange juice.']\n",
      " > Text splitted to sentences.\n",
      "['Brain examined for thrombosis, clot or hemorrhage.']\n",
      " > Text splitted to sentences.\n",
      "['A roll of wire lay near the wall.']\n",
      " > Text splitted to sentences.\n",
      "['We saw eight tiny icicles below our roof.']\n",
      "Generating audio for sentence: Coconut cream pie makes a nice dessert.\n",
      " > Text splitted to sentences.\n",
      "['Coconut cream pie makes a nice dessert.']\n",
      "Generating audio for sentence: The roof of the command post began to buckle.\n",
      " > Text splitted to sentences.\n",
      "['The roof of the command post began to buckle.']\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (53) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (53) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (53) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (53) at non-singleton dimension 1\n",
      "Generating audio for sentence: A roll of wire lay near the wall.\n",
      "Generating audio for sentence: Brain examined for thrombosis, clot or hemorrhage.\n",
      "Generating audio for sentence: We saw eight tiny icicles below our roof.\n",
      " > Text splitted to sentences.\n",
      "['Brain examined for thrombosis, clot or hemorrhage.']\n",
      " > Text splitted to sentences.\n",
      "['A roll of wire lay near the wall.']\n",
      " > Text splitted to sentences.\n",
      "['We saw eight tiny icicles below our roof.']\n",
      "Generating audio for sentence: It's hard to tell an original from a forgery.\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (53) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "[\"It's hard to tell an original from a forgery.\"]\n",
      "Generating audio for sentence: A screwdriver is made from vodka and orange juice.\n",
      " > Text splitted to sentences.\n",
      "['A screwdriver is made from vodka and orange juice.']\n",
      "Failed to generate or normalize audio: The size of tensor a (33) must match the size of tensor b (41) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (33) must match the size of tensor b (41) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (33) must match the size of tensor b (41) at non-singleton dimension 1\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Generating audio for sentence: We're not drunkards, she said.\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (33) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "[\"We're not drunkards, she said.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (33) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (33) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: Coconut cream pie makes a nice dessert.\n",
      "Generating audio for sentence: Check the overnighters out.\n",
      " > Text splitted to sentences.\n",
      "['Coconut cream pie makes a nice dessert.']\n",
      " > Text splitted to sentences.\n",
      "['Check the overnighters out.']\n",
      "Generating audio for sentence: The roof of the command post began to buckle.\n",
      " > Text splitted to sentences.\n",
      "['The roof of the command post began to buckle.']\n",
      "Failed to generate or normalize audio: The size of tensor a (30) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (30) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (30) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 30 but got size 27 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: The size of tensor a (53) must match the size of tensor b (39) at non-singleton dimension 1\n",
      " > Processing time: 0.949530839920044\n",
      " > Real-time factor: 0.44433690620197297\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 0.9693319797515869\n",
      " > Real-time factor: 0.4280232728597102\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "   > Decoder stopped with `max_decoder_steps` 10000\n",
      "   > Decoder stopped with `max_decoder_steps` 10000\n",
      " > Processing time: 56.14725685119629\n",
      " > Real-time factor: 0.4812509770690978\n",
      " > Processing time: 56.550971031188965\n",
      " > Real-time factor: 0.4847113036188531\n",
      "Processing batch 6: ['MMDS0', 'MWSB0', 'MTDB0', 'MJJJ0', 'MJAC0', 'MDSJ0', 'MRML0', 'MRJH0', 'MDPK0', 'MZMB0']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: Would a tomboy often play outdoors?\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ljspeech_tacotron2-DDC/MRML0.wav already exists. Skipping.\n",
      "Output file ../Data/ttsOutputs/tts_models_en_ljspeech_tacotron2-DDC/MZMB0.wav already exists. Skipping.\n",
      "Generating audio for sentence: The enemy did not veer.\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "['Would a tomboy often play outdoors?']\n",
      "Generating audio for sentence: No more startling contrast to a system of sullen satellites could be imagined.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Generating audio for sentence: No fasciculations or sensory defects were found.\n",
      " > Text splitted to sentences.\n",
      "['No more startling contrast to a system of sullen satellites could be imagined.']\n",
      " > Text splitted to sentences.\n",
      "['The enemy did not veer.']\n",
      "Generating audio for sentence: Tugboats are capable of hauling huge loads.\n",
      " > Text splitted to sentences.\n",
      "['No fasciculations or sensory defects were found.']\n",
      "Generating audio for sentence: An adult male baboon's teeth are not suitable for eating shellfish.\n",
      "Generating audio for sentence: That stinging vapor was caused by chloride vaporization.\n",
      " > Text splitted to sentences.\n",
      "['Tugboats are capable of hauling huge loads.']\n",
      " > Text splitted to sentences.\n",
      "[\"An adult male baboon's teeth are not suitable for eating shellfish.\"]\n",
      " > Text splitted to sentences.\n",
      "['That stinging vapor was caused by chloride vaporization.']\n",
      "Failed to generate or normalize audio: The size of tensor a (43) must match the size of tensor b (23) at non-singleton dimension 1\n",
      "Generating audio for sentence: The enemy did not veer.\n",
      " > Text splitted to sentences.\n",
      "['The enemy did not veer.']\n",
      "Failed to generate or normalize audio: The size of tensor a (78) must match the size of tensor b (48) at non-singleton dimension 1\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Failed to generate or normalize audio: The size of tensor a (78) must match the size of tensor b (48) at non-singleton dimension 1\n",
      "Generating audio for sentence: Tugboats are capable of hauling huge loads.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "['Tugboats are capable of hauling huge loads.']\n",
      "Failed to generate or normalize audio: The size of tensor a (78) must match the size of tensor b (56) at non-singleton dimension 1\n",
      "Generating audio for sentence: Would a tomboy often play outdoors?\n",
      " > Text splitted to sentences.\n",
      "['Would a tomboy often play outdoors?']\n",
      "Failed to generate or normalize audio: Expected size for first two dimensions of batch2 tensor to be: [1, 78] but got: [1, 56].\n",
      "Generating audio for sentence: No more startling contrast to a system of sullen satellites could be imagined.\n",
      "Failed to generate or normalize audio: Expected size for first two dimensions of batch2 tensor to be: [1, 78] but got: [1, 56].\n",
      "Generating audio for sentence: That stinging vapor was caused by chloride vaporization.\n",
      " > Text splitted to sentences.\n",
      "['No more startling contrast to a system of sullen satellites could be imagined.']\n",
      " > Text splitted to sentences.\n",
      "['That stinging vapor was caused by chloride vaporization.']\n",
      "Failed to generate or normalize audio: The size of tensor a (23) must match the size of tensor b (67) at non-singleton dimension 1\n",
      "Generating audio for sentence: No fasciculations or sensory defects were found.\n",
      " > Text splitted to sentences.\n",
      "['No fasciculations or sensory defects were found.']\n",
      "Failed to generate or normalize audio: The size of tensor a (43) must match the size of tensor b (35) at non-singleton dimension 1\n",
      "Generating audio for sentence: An adult male baboon's teeth are not suitable for eating shellfish.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 43 but got size 35 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: The size of tensor a (35) must match the size of tensor b (43) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "[\"An adult male baboon's teeth are not suitable for eating shellfish.\"]\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 56] at entry 0 and [1, 78] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 78] at entry 0 and [1, 67] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 56] at entry 0 and [1, 78] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 78] at entry 0 and [1, 67] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 78] at entry 0 and [1, 67] at entry 2\n",
      " > Processing time: 2.083095073699951\n",
      " > Real-time factor: 0.616440927301427\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 7: ['FKSR0', 'FDML0', 'MDWD0', 'MRCG0', 'MILB0', 'FJLR0', 'MTAB0', 'FMBG0', 'MMXS0', 'MRLJ1']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: This was easy for us.\n",
      "Generating audio for sentence: Critical equipment needs proper maintenance.\n",
      "Generating audio for sentence: Almost all colleges are now coeducational.\n",
      " > Text splitted to sentences.\n",
      "['This was easy for us.']\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "['Critical equipment needs proper maintenance.']\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "['Almost all colleges are now coeducational.']\n",
      "Generating audio for sentence: Those answers will be straightforward if you think them through carefully first.\n",
      "Generating audio for sentence: A toothpaste tube should be squeezed from the bottom.\n",
      "Generating audio for sentence: But that explanation is only partly true.\n",
      "Generating audio for sentence: The knifelike pain in his groin nearly brought him down again.\n",
      " > Text splitted to sentences.\n",
      "['But that explanation is only partly true.']\n",
      "Generating audio for sentence: Hello, boss, he said, and grinned.\n",
      " > Text splitted to sentences.\n",
      "['A toothpaste tube should be squeezed from the bottom.']\n",
      "Generating audio for sentence: A moth zig-zagged along the path through Otto's garden.\n",
      " > Text splitted to sentences.\n",
      "['Those answers will be straightforward if you think them through carefully first.']\n",
      " > Text splitted to sentences.\n",
      "['The knifelike pain in his groin nearly brought him down again.']\n",
      " > Text splitted to sentences.\n",
      "[\"A moth zig-zagged along the path through Otto's garden.\"]\n",
      " > Text splitted to sentences.\n",
      "['Hello, boss, he said, and grinned.']\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (21) at non-singleton dimension 1\n",
      "Generating audio for sentence: This was easy for us.\n",
      " > Text splitted to sentences.\n",
      "['This was easy for us.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 44 but got size 53 for tensor number 1 in the list.\n",
      "Generating audio for sentence: The knifelike pain in his groin nearly brought him down again.\n",
      " > Text splitted to sentences.\n",
      "['The knifelike pain in his groin nearly brought him down again.']\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (41) at non-singleton dimension 1\n",
      "Generating audio for sentence: Those answers will be straightforward if you think them through carefully first.\n",
      " > Text splitted to sentences.\n",
      "['Those answers will be straightforward if you think them through carefully first.']\n",
      "Failed to generate or normalize audio: Expected size for first two dimensions of batch2 tensor to be: [1, 34] but got: [1, 55].\n",
      "Generating audio for sentence: But that explanation is only partly true.\n",
      "Failed to generate or normalize audio: Expected size for first two dimensions of batch2 tensor to be: [1, 34] but got: [1, 55].\n",
      "Failed to generate or normalize audio: The size of tensor a (21) must match the size of tensor b (34) at non-singleton dimension 1\n",
      "Generating audio for sentence: A moth zig-zagged along the path through Otto's garden.\n",
      " > Text splitted to sentences.\n",
      "['But that explanation is only partly true.']\n",
      "Generating audio for sentence: Hello, boss, he said, and grinned.\n",
      " > Text splitted to sentences.\n",
      "['Hello, boss, he said, and grinned.']\n",
      " > Text splitted to sentences.\n",
      "[\"A moth zig-zagged along the path through Otto's garden.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (21) must match the size of tensor b (34) at non-singleton dimension 1\n",
      "Generating audio for sentence: A toothpaste tube should be squeezed from the bottom.\n",
      " > Text splitted to sentences.\n",
      "['A toothpaste tube should be squeezed from the bottom.']\n",
      "Failed to generate or normalize audio: Expected size for first two dimensions of batch2 tensor to be: [1, 41] but got: [1, 34].\n",
      "Generating audio for sentence: Critical equipment needs proper maintenance.\n",
      " > Text splitted to sentences.\n",
      "['Critical equipment needs proper maintenance.']\n",
      "Failed to generate or normalize audio: The size of tensor a (80) must match the size of tensor b (41) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (80) must match the size of tensor b (41) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (55) must match the size of tensor b (80) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (55) must match the size of tensor b (80) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (55) must match the size of tensor b (80) at non-singleton dimension 1\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Generating audio for sentence: Almost all colleges are now coeducational.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "['Almost all colleges are now coeducational.']\n",
      "Failed to generate or normalize audio: The size of tensor a (53) must match the size of tensor b (55) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (53) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 53] at entry 0 and [1, 44] at entry 1\n",
      " > Processing time: 2.391326904296875\n",
      " > Real-time factor: 0.5084936568406312\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 2.415864944458008\n",
      " > Real-time factor: 0.49654942230890264\n",
      " > Processing time: 2.4153339862823486\n",
      " > Real-time factor: 0.50365140714864\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 8: ['FJKL0', 'MBOM0', 'FLEH0', 'MBML0', 'MRGS0', 'FPAF0', 'MTXS0', 'FKDE0', 'MBEF0', 'MKJO0']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: The sheriff's swivel chair tilted back.\n",
      "Generating audio for sentence: Was it a birthday ball?\n",
      " > Text splitted to sentences.\n",
      "[\"The sheriff's swivel chair tilted back.\"]\n",
      " > Text splitted to sentences.\n",
      "['Was it a birthday ball?']\n",
      "Generating audio for sentence: Should giraffes be kept in small zoos?\n",
      " > Text splitted to sentences.\n",
      "['Should giraffes be kept in small zoos?']\n",
      "Generating audio for sentence: We could barely see the fjords through the snow flurries.\n",
      "Generating audio for sentence: Will you please confirm government policy regarding waste removal?\n",
      " > Text splitted to sentences.\n",
      "['We could barely see the fjords through the snow flurries.']\n",
      "Generating audio for sentence: Those who teach values first abolish cheating.\n",
      " > Text splitted to sentences.\n",
      "['Will you please confirm government policy regarding waste removal?']\n",
      "Generating audio for sentence: She asked with a reportorial gleam in her eye.\n",
      "Generating audio for sentence: Hey, come back, he shouted.\n",
      " > Text splitted to sentences.\n",
      "['Those who teach values first abolish cheating.']\n",
      " > Text splitted to sentences.\n",
      "['She asked with a reportorial gleam in her eye.']\n",
      " > Text splitted to sentences.\n",
      "['Hey, come back, he shouted.']\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Failed to generate or normalize audio: The size of tensor a (66) must match the size of tensor b (57) at non-singleton dimension 1\n",
      "Generating audio for sentence: Hey, come back, he shouted.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 66 but got size 57 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: The size of tensor a (66) must match the size of tensor b (57) at non-singleton dimension 1\n",
      "Generating audio for sentence: Was it a birthday ball?\n",
      " > Text splitted to sentences.\n",
      "['Hey, come back, he shouted.']\n",
      "Generating audio for sentence: Should giraffes be kept in small zoos?\n",
      " > Text splitted to sentences.\n",
      "['Should giraffes be kept in small zoos?']\n",
      " > Text splitted to sentences.\n",
      "['Was it a birthday ball?']\n",
      "Failed to generate or normalize audio: The size of tensor a (23) must match the size of tensor b (53) at non-singleton dimension 1\n",
      "Generating audio for sentence: Those who teach values first abolish cheating.\n",
      " > Text splitted to sentences.\n",
      "['Those who teach values first abolish cheating.']\n",
      "Failed to generate or normalize audio: The size of tensor a (23) must match the size of tensor b (53) at non-singleton dimension 1\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Failed to generate or normalize audio: The size of tensor a (23) must match the size of tensor b (53) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: The sheriff's swivel chair tilted back.\n",
      " > Text splitted to sentences.\n",
      "[\"The sheriff's swivel chair tilted back.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (38) must match the size of tensor b (23) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (38) must match the size of tensor b (23) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (38) must match the size of tensor b (23) at non-singleton dimension 1\n",
      "Generating audio for sentence: We could barely see the fjords through the snow flurries.\n",
      " > Text splitted to sentences.\n",
      "['We could barely see the fjords through the snow flurries.']\n",
      "Failed to generate or normalize audio: The size of tensor a (46) must match the size of tensor b (38) at non-singleton dimension 1\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Failed to generate or normalize audio: The size of tensor a (39) must match the size of tensor b (46) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 53] at entry 0 and [1, 23] at entry 1\n",
      "Generating audio for sentence: She asked with a reportorial gleam in her eye.\n",
      " > Text splitted to sentences.\n",
      "['She asked with a reportorial gleam in her eye.']\n",
      "Failed to generate or normalize audio: The size of tensor a (57) must match the size of tensor b (53) at non-singleton dimension 1\n",
      "Generating audio for sentence: Will you please confirm government policy regarding waste removal?\n",
      " > Text splitted to sentences.\n",
      "['Will you please confirm government policy regarding waste removal?']\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 38] at entry 0 and [1, 39] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 46] at entry 0 and [1, 66] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 46] at entry 0 and [1, 66] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 57] at entry 0 and [1, 46] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 57] at entry 0 and [1, 53] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 57] at entry 0 and [1, 53] at entry 1\n",
      " > Processing time: 47.82172703742981\n",
      " > Real-time factor: 0.5439041138695372\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 9: ['MJDA0', 'MRRE0', 'FTMG0', 'MDLM0', 'MJRA0', 'MJPM0', 'MDCM0', 'MDAC0', 'MTPF0', 'FJDM2']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: With this no loyal citizen can quarrel.\n",
      "Generating audio for sentence: Often you'll get back more than you put in.\n",
      "Generating audio for sentence: Etiquette mandates compliance with existing regulations.\n",
      " > Text splitted to sentences.\n",
      "[\"Often you'll get back more than you put in.\"]\n",
      " > Text splitted to sentences.\n",
      "['Etiquette mandates compliance with existing regulations.']\n",
      "Generating audio for sentence: Thick glue oozed out of the tube.\n",
      " > Text splitted to sentences.\n",
      "['With this no loyal citizen can quarrel.']\n",
      "Generating audio for sentence: An official deadline cannot be postponed.\n",
      " > Text splitted to sentences.\n",
      "['Thick glue oozed out of the tube.']\n",
      "Generating audio for sentence: Norwegian sweaters are made of lamb's wool.\n",
      " > Text splitted to sentences.\n",
      "['An official deadline cannot be postponed.']\n",
      " > Text splitted to sentences.\n",
      "[\"Norwegian sweaters are made of lamb's wool.\"]\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Generating audio for sentence: Does Hindu ideology honor cows?\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "['Does Hindu ideology honor cows?']\n",
      "Generating audio for sentence: Her classical performance gained critical acclaim.\n",
      " > Text splitted to sentences.\n",
      "['Her classical performance gained critical acclaim.']\n",
      "Failed to generate or normalize audio: The size of tensor a (43) must match the size of tensor b (31) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (43) must match the size of tensor b (31) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (43) must match the size of tensor b (31) at non-singleton dimension 1\n",
      "Generating audio for sentence: Does Hindu ideology honor cows?\n",
      "Generating audio for sentence: Thick glue oozed out of the tube.\n",
      " > Text splitted to sentences.\n",
      "['Does Hindu ideology honor cows?']\n",
      " > Text splitted to sentences.\n",
      "['Thick glue oozed out of the tube.']\n",
      "Generating audio for sentence: With this no loyal citizen can quarrel.\n",
      " > Text splitted to sentences.\n",
      "['With this no loyal citizen can quarrel.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 43 but got size 44 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: The size of tensor a (43) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Generating audio for sentence: Etiquette mandates compliance with existing regulations.\n",
      " > Text splitted to sentences.\n",
      "['Etiquette mandates compliance with existing regulations.']\n",
      "Generating audio for sentence: Often you'll get back more than you put in.\n",
      " > Text splitted to sentences.\n",
      "[\"Often you'll get back more than you put in.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (50) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (50) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Generating audio for sentence: Norwegian sweaters are made of lamb's wool.\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      " > Text splitted to sentences.\n",
      "[\"Norwegian sweaters are made of lamb's wool.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (33) must match the size of tensor b (31) at non-singleton dimension 1\n",
      "Generating audio for sentence: An official deadline cannot be postponed.\n",
      " > Text splitted to sentences.\n",
      "['An official deadline cannot be postponed.']\n",
      "Failed to generate or normalize audio: The size of tensor a (39) must match the size of tensor b (33) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (33) must match the size of tensor b (31) at non-singleton dimension 1\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (43) must match the size of tensor b (39) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (39) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (43) must match the size of tensor b (39) at non-singleton dimension 1\n",
      "Generating audio for sentence: Her classical performance gained critical acclaim.\n",
      " > Text splitted to sentences.\n",
      "['Her classical performance gained critical acclaim.']\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (41) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (41) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (41) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (41) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (41) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 44] at entry 0 and [1, 50] at entry 1\n",
      " > Processing time: 1.0489678382873535\n",
      " > Real-time factor: 0.31364912174870013\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Processing batch 10: ['FCMM0', 'MCDD0', 'MTLC0', 'MAJP0', 'MAFM0', 'FALR0', 'MSAH1', 'MMAA0', 'MKXL0', 'MVJH0']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Generating audio for sentence: Is it larger or fancier than you really need?\n",
      "Generating audio for sentence: Clapping spurs to the bronc, he set off at a sharp canter, with growing alarm.\n",
      " > Text splitted to sentences.\n",
      "['Clapping spurs to the bronc, he set off at a sharp canter, with growing alarm.']\n",
      "Generating audio for sentence: We saw eight tiny icicles below our roof.\n",
      " > Text splitted to sentences.\n",
      "['Is it larger or fancier than you really need?']\n",
      " > Text splitted to sentences.\n",
      "['We saw eight tiny icicles below our roof.']\n",
      "Generating audio for sentence: While waiting for Chipper she crisscrossed the square many times.\n",
      "Generating audio for sentence: Impressions often appear in a symbolic form and cannot be taken at face value.\n",
      " > Text splitted to sentences.\n",
      "['While waiting for Chipper she crisscrossed the square many times.']\n",
      " > Text splitted to sentences.\n",
      "['Impressions often appear in a symbolic form and cannot be taken at face value.']\n",
      "Generating audio for sentence: Like enough we'll all be up on top by sundown.\n",
      "Generating audio for sentence: To be passive, to be girlishly shy was palpably absurd.\n",
      " > Text splitted to sentences.\n",
      "['To be passive, to be girlishly shy was palpably absurd.']\n",
      " > Text splitted to sentences.\n",
      "[\"Like enough we'll all be up on top by sundown.\"]\n",
      "Generating audio for sentence: Rich purchased several signed lithographs.\n",
      "Generating audio for sentence: Another put sex on a dollars-and-cents basis.\n",
      " > Text splitted to sentences.\n",
      "['Rich purchased several signed lithographs.']\n",
      " > Text splitted to sentences.\n",
      "['Another put sex on a dollars-and-cents basis.']\n",
      "Failed to generate or normalize audio: The size of tensor a (41) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Failed to generate or normalize audio: The size of tensor a (41) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Generating audio for sentence: Is it larger or fancier than you really need?\n",
      " > Text splitted to sentences.\n",
      "['Is it larger or fancier than you really need?']\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (65) must match the size of tensor b (42) at non-singleton dimension 1\n",
      "Generating audio for sentence: We saw eight tiny icicles below our roof.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 45 but got size 78 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 45 but got size 78 for tensor number 1 in the list.\n",
      " > Text splitted to sentences.\n",
      "['We saw eight tiny icicles below our roof.']\n",
      "Generating audio for sentence: Like enough we'll all be up on top by sundown.\n",
      " > Text splitted to sentences.\n",
      "[\"Like enough we'll all be up on top by sundown.\"]\n",
      "Generating audio for sentence: To be passive, to be girlishly shy was palpably absurd.\n",
      "Failed to generate or normalize audio: The size of tensor a (78) must match the size of tensor b (65) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['To be passive, to be girlishly shy was palpably absurd.']\n",
      "Generating audio for sentence: Rich purchased several signed lithographs.\n",
      " > Text splitted to sentences.\n",
      "['Rich purchased several signed lithographs.']\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (78) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (78) at non-singleton dimension 1\n",
      "Generating audio for sentence: Another put sex on a dollars-and-cents basis.\n",
      "Generating audio for sentence: Clapping spurs to the bronc, he set off at a sharp canter, with growing alarm.\n",
      " > Text splitted to sentences.\n",
      "['Another put sex on a dollars-and-cents basis.']\n",
      " > Text splitted to sentences.\n",
      "['Clapping spurs to the bronc, he set off at a sharp canter, with growing alarm.']\n",
      "Failed to generate or normalize audio: The size of tensor a (44) must match the size of tensor b (78) at non-singleton dimension 1\n",
      "Generating audio for sentence: Impressions often appear in a symbolic form and cannot be taken at face value.\n",
      " > Text splitted to sentences.\n",
      "['Impressions often appear in a symbolic form and cannot be taken at face value.']\n",
      "Failed to generate or normalize audio: The size of tensor a (46) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (46) must match the size of tensor b (44) at non-singleton dimension 1\n",
      "Generating audio for sentence: While waiting for Chipper she crisscrossed the square many times.\n",
      " > Text splitted to sentences.\n",
      "['While waiting for Chipper she crisscrossed the square many times.']\n",
      "Failed to generate or normalize audio: The size of tensor a (41) must match the size of tensor b (46) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (42) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (45) must match the size of tensor b (42) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (78) must match the size of tensor b (45) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 45 but got size 78 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 45 but got size 78 for tensor number 1 in the list.\n",
      "Failed to generate or normalize audio: The size of tensor a (65) must match the size of tensor b (78) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (78) must match the size of tensor b (65) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: Expected size for first two dimensions of batch2 tensor to be: [1, 78] but got: [1, 65].\n",
      "Processing batch 11: ['FRLL0', 'MRMH0', 'MJAI0', 'MJDM0', 'FPAB1', 'MCXM0', 'MJDG0', 'MTRR0', 'MRTC0', 'FTLG0']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: They all like long hot showers.\n",
      "Generating audio for sentence: Each stag surely finds a big fawn.\n",
      " > Text splitted to sentences.\n",
      "['Each stag surely finds a big fawn.']\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: They were all good men.\n",
      " > Text splitted to sentences.\n",
      "['They all like long hot showers.']\n",
      " > Text splitted to sentences.\n",
      "['They were all good men.']\n",
      "Generating audio for sentence: Time and space have both become cinematic.\n",
      "Generating audio for sentence: Curiosity and mediocrity seldom coexist.\n",
      " > Text splitted to sentences.\n",
      "['Curiosity and mediocrity seldom coexist.']\n",
      "Generating audio for sentence: The speech symposium might begin Monday.\n",
      " > Text splitted to sentences.\n",
      "['Time and space have both become cinematic.']\n",
      " > Text splitted to sentences.\n",
      "['The speech symposium might begin Monday.']\n",
      "Generating audio for sentence: Alimony harms a divorced man's wealth.\n",
      "Generating audio for sentence: A screwdriver is made from vodka and orange juice.\n",
      "Generating audio for sentence: Y'all wanna walk -- walk, he said.\n",
      " > Text splitted to sentences.\n",
      "[\"Alimony harms a divorced man's wealth.\"]\n",
      " > Text splitted to sentences.\n",
      "[\"Y'all wanna walk -- walk, he said.\"]\n",
      " > Text splitted to sentences.\n",
      "['A screwdriver is made from vodka and orange juice.']\n",
      "Failed to generate or normalize audio: The size of tensor a (53) must match the size of tensor b (34) at non-singleton dimension 1\n",
      "Generating audio for sentence: Curiosity and mediocrity seldom coexist.\n",
      " > Text splitted to sentences.\n",
      "['Curiosity and mediocrity seldom coexist.']\n",
      "Failed to generate or normalize audio: The size of tensor a (53) must match the size of tensor b (34) at non-singleton dimension 1\n",
      "Generating audio for sentence: They all like long hot showers.\n",
      "Failed to generate or normalize audio: The size of tensor a (53) must match the size of tensor b (34) at non-singleton dimension 1\n",
      " > Text splitted to sentences.\n",
      "['They all like long hot showers.']\n",
      "Generating audio for sentence: They were all good men.\n",
      " > Text splitted to sentences.\n",
      "['They were all good men.']\n",
      "Failed to generate or normalize audio: The size of tensor a (40) must match the size of tensor b (53) at non-singleton dimension 1\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Failed to generate or normalize audio: The size of tensor a (31) must match the size of tensor b (40) at non-singleton dimension 1\n",
      "Generating audio for sentence: The speech symposium might begin Monday.\n",
      " > Text splitted to sentences.\n",
      "['The speech symposium might begin Monday.']\n",
      "Failed to generate or normalize audio: Sizes of tensors must match except in dimension 1. Expected size 31 but got size 23 for tensor number 1 in the list.\n",
      "Generating audio for sentence: A screwdriver is made from vodka and orange juice.\n",
      " > Text splitted to sentences.\n",
      "['A screwdriver is made from vodka and orange juice.']\n",
      "Failed to generate or normalize audio: The size of tensor a (23) must match the size of tensor b (31) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (31) must match the size of tensor b (23) at non-singleton dimension 1\n",
      "Generating audio for sentence: Time and space have both become cinematic.\n",
      "Generating audio for sentence: Each stag surely finds a big fawn.\n",
      " > Text splitted to sentences.\n",
      "['Time and space have both become cinematic.']\n",
      " > Text splitted to sentences.\n",
      "['Each stag surely finds a big fawn.']\n",
      "Failed to generate or normalize audio: The size of tensor a (40) must match the size of tensor b (53) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: The size of tensor a (42) must match the size of tensor b (50) at non-singleton dimension 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 31] at entry 0 and [1, 53] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 50] at entry 0 and [1, 31] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 40] at entry 0 and [1, 42] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 53] at entry 0 and [1, 42] at entry 1\n",
      "Failed to generate or normalize audio: stack expects each tensor to be equal size, but got [1, 50] at entry 0 and [1, 31] at entry 1\n",
      "Generating audio for sentence: Y'all wanna walk -- walk, he said.\n",
      " > Text splitted to sentences.\n",
      "[\"Y'all wanna walk -- walk, he said.\"]\n",
      "Generating audio for sentence: Alimony harms a divorced man's wealth.\n",
      " > Text splitted to sentences.\n",
      "[\"Alimony harms a divorced man's wealth.\"]\n",
      "Failed to generate or normalize audio: The size of tensor a (31) must match the size of tensor b (38) at non-singleton dimension 1\n",
      " > Processing time: 1.4801511764526367\n",
      " > Real-time factor: 0.7366678728959155\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 1.4994440078735352\n",
      " > Real-time factor: 0.7506070735018945\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 1.5002501010894775\n",
      " > Real-time factor: 0.7423813897895641\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Processing time: 3.6878840923309326\n",
      " > Real-time factor: 1.069296289657809\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
      "Processing batch 12: ['FDTD0', 'MTPR0', 'MREH1', 'FSDC0', 'MTAT1', 'MGES0', 'MTKD0', 'MRJM0', 'MDHL0', 'MPGH0']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: How's your sunburn now?\n",
      "Generating audio for sentence: We like bleu cheese but Victor prefers swiss cheese.\n",
      "Generating audio for sentence: The Boston Ballet overcame their funding shortage.\n",
      " > Text splitted to sentences.\n",
      "['We like bleu cheese but Victor prefers swiss cheese.']\n",
      "Generating audio for sentence: Gwen planted green beans in her vegetable garden.\n",
      " > Text splitted to sentences.\n",
      "['The Boston Ballet overcame their funding shortage.']\n",
      " > Text splitted to sentences.\n",
      "['Gwen planted green beans in her vegetable garden.']\n",
      "Generating audio for sentence: The keelson, made of two three-inch widths, is next installed.\n",
      " > Text splitted to sentences.\n",
      "[\"How's your sunburn now?\"]\n",
      "Generating audio for sentence: In the long run, it pays to buy quality clothing.\n",
      " > Text splitted to sentences.\n",
      "['The keelson, made of two three-inch widths, is next installed.']\n",
      " > Text splitted to sentences.\n",
      "['In the long run, it pays to buy quality clothing.']\n",
      "Generating audio for sentence: They find deep pessimism in them.\n",
      "Generating audio for sentence: Do atypical farmers grow oats?\n",
      " > Text splitted to sentences.\n",
      "['They find deep pessimism in them.']\n",
      "Generating audio for sentence: We plan to build a new beverage plant.\n",
      " > Text splitted to sentences.\n",
      "['Do atypical farmers grow oats?']\n",
      " > Text splitted to sentences.\n",
      "['We plan to build a new beverage plant.']\n",
      "Generating audio for sentence: The cartoon features a muskrat and a tadpole.\n",
      " > Text splitted to sentences.\n",
      "['The cartoon features a muskrat and a tadpole.']\n",
      " > Processing time: 1.2446818351745605\n",
      " > Real-time factor: 0.8179910129231956\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 1.2972500324249268\n",
      " > Real-time factor: 0.8934396306524749\n",
      " > Processing time: 1.2914397716522217\n",
      " > Real-time factor: 0.8297274756681668\n",
      " > Processing time: 1.3029539585113525\n",
      " > Real-time factor: 0.8902495905173315\n",
      " > Processing time: 1.2998569011688232\n",
      " > Real-time factor: 0.8881335111171466\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Processing time: 1.3128077983856201\n",
      " > Real-time factor: 0.8562296484383259\n",
      " > Using model: freevc\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Processing time: 1.3161389827728271\n",
      " > Real-time factor: 0.9441978321883406\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Using model: freevc\n",
      " > Processing time: 1.328376054763794\n",
      " > Real-time factor: 0.9451049305479368\n",
      " > Using model: freevc\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 1.3401110172271729\n",
      " > Real-time factor: 0.9613953647143142\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 1.3596842288970947\n",
      " > Real-time factor: 0.8801384818923479\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.03 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.05 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.05 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.05 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.04 seconds.\n",
      "Processing batch 13: ['MWAD0', 'FKKH0', 'MJMA0', 'FKDW0', 'MREE0', 'FLKM0', 'MAEB0', 'MJBG0', 'MJEB1', 'MBCG0']\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Generating audio for sentence: Vital questions would be quickly answered according to a preprepared agenda.Generating audio for sentence: Don't ask me to carry an oily rag like that.\n",
      "Generating audio for sentence: Critical equipment needs proper maintenance.\n",
      "Generating audio for sentence: His black hat with its wide brim, high crown, and fur trim rode high.\n",
      "\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      "Generating audio for sentence: She had your dark suit in greasy wash water all year.\n",
      " > Text splitted to sentences.\n",
      " > Text splitted to sentences.\n",
      " > Text splitted to sentences.\n",
      " > Text splitted to sentences.\n",
      " > Text splitted to sentences.\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      " > Text splitted to sentences.\n",
      "[\"Don't ask me to carry an oily rag like that.\"]\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "['His black hat with its wide brim, high crown, and fur trim rode high.']\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "['Vital questions would be quickly answered according to a preprepared agenda.']\n",
      "['Critical equipment needs proper maintenance.']\n",
      " > Text splitted to sentences.\n",
      "['She had your dark suit in greasy wash water all year.']\n",
      "Generating audio for sentence: But he was very much like his associates in his hatred of camp routine.\n",
      " > Text splitted to sentences.\n",
      "['But he was very much like his associates in his hatred of camp routine.']\n",
      " > Processing time: 109.02280402183533\n",
      " > Real-time factor: 1.351130401638401\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 109.83341908454895\n",
      " > Real-time factor: 1.354549918796313\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 110.49205279350281\n",
      " > Real-time factor: 1.3632582813866627\n",
      " > Processing time: 110.81254005432129\n",
      " > Real-time factor: 1.3854709164197008\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Processing time: 111.03852891921997 > Using model: freevc\n",
      "\n",
      " > Real-time factor: 1.3631664187248904\n",
      " > Processing time: 111.08989477157593\n",
      " > Real-time factor: 1.3688697457290089\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Processing time: 111.42829179763794\n",
      " > Real-time factor: 1.3706864462579758\n",
      " > Using model: freevc\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Using model: freevc\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Processing time: 111.6985251903534\n",
      " > Real-time factor: 1.371268874350426\n",
      " > Processing time: 111.75950479507446\n",
      " > Real-time factor: 1.3706499794935614\n",
      " > Processing time: 112.0314929485321\n",
      " > Real-time factor: 1.375356558786497\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.03 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.03 seconds.\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.03 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
      "Loaded the voice encoder model on cpu in 0.21 seconds.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
