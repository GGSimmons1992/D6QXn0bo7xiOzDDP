{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "060efaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(5000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "from pydub import AudioSegment\n",
    "from TTS.api import TTS\n",
    "from TTS.utils.manage import ModelManager\n",
    "import os\n",
    "import torch\n",
    "from TTS.utils.radam import RAdam\n",
    "import numpy.core.multiarray\n",
    "import shutil\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "torch.serialization.add_safe_globals([RAdam, numpy.core.multiarray.scalar])\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../Src/\")\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9a81d-2d31-45b9-a4f2-f12f6183c44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "#dataSet = pd.read_csv('../Data/train_data.csv')\n",
    "#dataSet[dataSet['speaker_id'] == 'MMDM0']\n",
    "# outputDF = pd.read_csv('../Data/ttsOutputs/tts_models_en_ljspeech_tacotron2-DDC_generatedSentences.csv')\n",
    "# print(outputDF.shape[0])\n",
    "# uniqueSpeakers = outputDF['speakerId'].unique()\n",
    "# print(len(uniqueSpeakers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c0a27-d4ad-4074-8feb-7bd8bb600f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCsv(dataset):\n",
    "    return pd.read_csv(f'../Data/{dataset}_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41cf41d-3b0b-48cf-8bd3-34eb6b306a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeakers(df):\n",
    "    speakerIds = df['speaker_id']\n",
    "    return list(set(speakerIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d89ff-453c-487a-933e-1d5a936f53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesBySpeaker(df,speakerId):\n",
    "    return df[df['speaker_id']==speakerId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefcf4c0-622e-45e9-b934-8782e0a4be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenateAudio(speakerId, speakerDF):\n",
    "    if speakerDF.empty:\n",
    "        print(f\"Empty DataFrame for speaker {speakerId}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    finalAudioFile = f'../Data/concatenatedInputs/{speakerId}.wav'\n",
    "    audioData = speakerDF[speakerDF['filename'].str.endswith('.wav', na=False)]\n",
    "\n",
    "    if audioData.empty:\n",
    "        print(f\"No .wav files for speaker {speakerId}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    audioFileList = audioData['path_from_data_dir']\n",
    "\n",
    "    if not exists(finalAudioFile):\n",
    "        concat_audio = AudioSegment.empty()\n",
    "    else:\n",
    "        concat_audio = AudioSegment.from_wav(finalAudioFile)\n",
    "    for audioFile in audioFileList:\n",
    "        try:\n",
    "            audio = AudioSegment.from_wav(f'../Data/data/{audioFile}') + AudioSegment.silent(duration=1000)\n",
    "            concat_audio += audio\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {audioFile}: {e}\")\n",
    "\n",
    "    if len(concat_audio) > 0:\n",
    "        concat_audio.export(finalAudioFile, format='wav')\n",
    "    else:\n",
    "        print(f\"No valid audio for speaker {speakerId}, nothing exported.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSentenceFromFile(sentenceFile):\n",
    "    try:\n",
    "        with open(f'../Data/data/{sentenceFile}', 'r') as file:\n",
    "            return \" \".join(file.read().strip().split(\" \")[2:])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read sentence file {sentenceFile}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31952130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAndNormalizeAudio(tts, sentence, inputAudioFile, outputAudioFile):\n",
    "    try:\n",
    "        print(f\"Generating audio for sentence: {sentence}\")\n",
    "        tts.tts_with_vc_to_file(\n",
    "            text=sentence,\n",
    "            file_path=outputAudioFile,\n",
    "            speaker_wav=inputAudioFile\n",
    "        )\n",
    "        if not exists(outputAudioFile):\n",
    "            print(f\"Warning: Output file {outputAudioFile} was not created.\")\n",
    "            return False\n",
    "\n",
    "        # Normalize the generated audio\n",
    "        original_audio = AudioSegment.from_wav(inputAudioFile)\n",
    "        generated_audio = AudioSegment.from_wav(outputAudioFile)\n",
    "\n",
    "        gain = original_audio.dBFS - generated_audio.dBFS\n",
    "        normalized_audio = generated_audio.apply_gain(gain)\n",
    "\n",
    "        # Export the normalized audio back to the same file\n",
    "        normalized_audio.export(outputAudioFile, format='wav')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to generate or normalize audio: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d0bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveGeneratedSentences(speakerSentences, model_dir_name, modelDirectory):\n",
    "    outputFile = f'../Data/ttsOutputs/{model_dir_name}_generatedSentences.csv'\n",
    "    if speakerSentences:\n",
    "        try:\n",
    "            pd.DataFrame(speakerSentences).to_csv(\n",
    "                outputFile, index=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save generated sentences: {e}\")\n",
    "            shutil.rmtree(modelDirectory, ignore_errors=True)\n",
    "    if not exists(outputFile):\n",
    "        print(f\"Warning: Output file {outputFile} was not created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGeneratedSentencesFromJson(speakerSentencesPath):\n",
    "    if exists(speakerSentencesPath):\n",
    "        with open(speakerSentencesPath, 'r') as f:\n",
    "            speakerSentences = json.load(f)\n",
    "    else:\n",
    "        speakerSentences = []\n",
    "    return speakerSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9449a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTTS(model):\n",
    "    try:\n",
    "        # Scoped override of torch.load\n",
    "        original_torch_load = torch.load\n",
    "        torch.load = lambda *args, **kwargs: original_torch_load(*args, weights_only=False, **kwargs)\n",
    "        tts = TTS(model_name=model, progress_bar=False, gpu=False)\n",
    "        result = tts\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load TTS model {model}: {e}\")\n",
    "        result = None\n",
    "    finally:\n",
    "        torch.load = original_torch_load  # Restore the original torch.load\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6ff992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_speaker(speaker, trainDF, tts, modelDirectory):\n",
    "    outputFilePath = f'{modelDirectory}/{speaker}.wav'\n",
    "    if exists(outputFilePath):\n",
    "        print(f\"Output file {outputFilePath} already exists. Skipping.\")\n",
    "        return None\n",
    "    speakerDF = getFilesBySpeaker(trainDF, speaker)\n",
    "    if speakerDF.empty:\n",
    "        print(f\"No data for speaker {speaker}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    textFiles = speakerDF[speakerDF['path_from_data_dir'].str.contains('.TXT', na=False)]\n",
    "    if textFiles.empty:\n",
    "        print(f\"No valid sentences for speaker {speaker}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    chosenSentenceFile = np.random.choice(textFiles['path_from_data_dir'])\n",
    "    chosenSentence = readSentenceFromFile(chosenSentenceFile)\n",
    "    if not chosenSentence:\n",
    "        print(f\"Chosen sentence for speaker {speaker} is empty. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    audioFile = f'../Data/concatenatedInputs/{speaker}.wav'\n",
    "    if not exists(audioFile):\n",
    "        print(f\"Audio file for {speaker} does not exist. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    if generateAndNormalizeAudio(tts, chosenSentence, audioFile, outputFilePath):\n",
    "        return {'speakerId': speaker, 'generatedSentence': chosenSentence}\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6506f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAudioInBatches(speakers, trainDF, batch_size=10):\n",
    "    if trainDF.empty or not speakers:\n",
    "        print(\"Empty dataset or no speakers provided. Exiting.\")\n",
    "        return\n",
    "\n",
    "    manager = ModelManager()\n",
    "    englishModels = [model for model in manager.list_models() if \"/en/\" in model]\n",
    "\n",
    "    if not englishModels:\n",
    "        print(\"No English models found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    for model in englishModels:\n",
    "        print(f\"Processing model: {model}\")\n",
    "        model_dir_name = model.replace(\"/\", \"_\")\n",
    "        outputCSVFile = f'../Data/ttsOutputs/{model_dir_name}_generatedSentences.csv'\n",
    "        if exists(outputCSVFile):\n",
    "            outputDF = pd.read_csv(outputCSVFile)\n",
    "            processed_speakers = set(outputDF['speakerId'])\n",
    "            missing_speakers = set(speakers) - processed_speakers\n",
    "            if not missing_speakers:\n",
    "                print(f\"All speakers processed for model {model}. Skipping.\")\n",
    "                continue\n",
    "        \n",
    "        modelDirectory = f'../Data/ttsOutputs/{model_dir_name}'\n",
    "        os.makedirs(modelDirectory, exist_ok=True)\n",
    "        speakerSentencesPath = f'../Data/ttsOutputs/{model_dir_name}_generatedSentences.json'\n",
    "        speakerSentences = loadGeneratedSentencesFromJson(speakerSentencesPath)\n",
    "\n",
    "        for i in range(0, len(speakers), batch_size):\n",
    "            batch = speakers[i:i + batch_size]\n",
    "            print(f\"Processing batch {i // batch_size + 1}: {batch}\")\n",
    "\n",
    "            tts = generateTTS(model)\n",
    "            if tts is None:\n",
    "                print(f\"Failed to generate TTS for model {model}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            with ThreadPoolExecutor(max_workers=batch_size) as executor:\n",
    "                futures = [\n",
    "                    executor.submit(process_speaker, speaker, trainDF, tts, modelDirectory)\n",
    "                    for speaker in batch\n",
    "                ]\n",
    "                for future in as_completed(futures):\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        speakerSentences.append(result)\n",
    "                        with open(speakerSentencesPath, 'w') as f:\n",
    "                            json.dump(speakerSentences, f)\n",
    "\n",
    "            saveGeneratedSentences(speakerSentences, model_dir_name, modelDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7e707-4a0d-4f85-8a9c-ae9694d4a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    trainDF = readCsv('train')\n",
    "    speakers = getSpeakers(trainDF)\n",
    "    if not exists('../Data/concatenatedInputs'):\n",
    "        os.makedirs('../Data/concatenatedInputs')\n",
    "        for speaker in speakers:\n",
    "            speakerDF = getFilesBySpeaker(trainDF, speaker)\n",
    "            concatenateAudio(speaker, speakerDF)\n",
    "    if not exists('../Data/ttsOutputs/'):\n",
    "        os.makedirs('../Data/ttsOutputs/')\n",
    "    \n",
    "    # Process speakers in batches\n",
    "    generateAudioInBatches(speakers, trainDF, batch_size=10)\n",
    "    \n",
    "    print(\"done\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768240ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
